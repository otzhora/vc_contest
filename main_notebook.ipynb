{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import json \n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import parallel_backend\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "from managing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>robot_gear_compression_diff_1</th>\n",
       "      <th>weapon_robot_armour_index_2</th>\n",
       "      <th>robot_gear_compression_diff_3</th>\n",
       "      <th>robot_gear_compression_diff_4</th>\n",
       "      <th>weapon_robot_punch_right_1</th>\n",
       "      <th>robot_gear_compression_diff_6</th>\n",
       "      <th>robot_gear_compression_diff_7</th>\n",
       "      <th>robot_gear_compression_diff_8</th>\n",
       "      <th>robot_gear_compression_diff_9</th>\n",
       "      <th>robot_gear_compression_diff_10</th>\n",
       "      <th>robot_gear_circulation_1</th>\n",
       "      <th>robot_gear_circulation_2</th>\n",
       "      <th>weapon_robot_punch_left_3</th>\n",
       "      <th>weapon_robot_armour_index_5</th>\n",
       "      <th>weapon_robot_armour_index_3</th>\n",
       "      <th>robot_gear_circulation_6</th>\n",
       "      <th>weapon_robot_punch_right_4</th>\n",
       "      <th>robot_gear_circulation_8</th>\n",
       "      <th>weapon_robot_punch_right_2</th>\n",
       "      <th>weapon_robot_gun_power_4</th>\n",
       "      <th>weapon_robot_gun_power_5</th>\n",
       "      <th>robot_gear_circulation_12</th>\n",
       "      <th>robot_gear_circulation_13</th>\n",
       "      <th>robot_gear_circulation_14</th>\n",
       "      <th>robot_gear_circulation_15</th>\n",
       "      <th>weapon_robot_gun_power_3</th>\n",
       "      <th>weapon_robot_punch_left_5</th>\n",
       "      <th>robot_gear_circulation_18</th>\n",
       "      <th>robot_gear_circulation_19</th>\n",
       "      <th>robot_gear_circulation_20</th>\n",
       "      <th>robot_gear_circulation_21</th>\n",
       "      <th>weapon_robot_punch_right_5</th>\n",
       "      <th>robot_gear_coef_1</th>\n",
       "      <th>weapon_robot_gun_power_2</th>\n",
       "      <th>robot_gear_compression_1</th>\n",
       "      <th>robot_gear_compression_2</th>\n",
       "      <th>robot_gear_compression_3</th>\n",
       "      <th>weapon_robot_armour_index_4</th>\n",
       "      <th>weapon_robot_eye_laser_emission_1</th>\n",
       "      <th>robot_gear_compression_6</th>\n",
       "      <th>robot_gear_temperature_diff_1</th>\n",
       "      <th>robot_gear_temperature_diff_2</th>\n",
       "      <th>robot_gear_temperature_diff_3</th>\n",
       "      <th>weapon_robot_eye_laser_sensor_1</th>\n",
       "      <th>robot_gear_temperature_diff_5</th>\n",
       "      <th>robot_gear_temperature_diff_6</th>\n",
       "      <th>robot_gear_temperature_1</th>\n",
       "      <th>robot_gear_temperature_2</th>\n",
       "      <th>robot_gear_temperature_3</th>\n",
       "      <th>robot_gear_temperature_4</th>\n",
       "      <th>weapon_robot_eye_laser_emission_4</th>\n",
       "      <th>weapon_robot_punch_right_3</th>\n",
       "      <th>weapon_robot_gun_power_1</th>\n",
       "      <th>robot_gear_temperature_8</th>\n",
       "      <th>robot_gear_temperature_9</th>\n",
       "      <th>robot_gear_temperature_10</th>\n",
       "      <th>robot_gear_temperature_11</th>\n",
       "      <th>robot_gear_temperature_12</th>\n",
       "      <th>robot_gear_temperature_13</th>\n",
       "      <th>robot_gear_temperature_14</th>\n",
       "      <th>robotic_circuits_speed_1</th>\n",
       "      <th>robotic_circuits_speed_2</th>\n",
       "      <th>robotic_circuits_speed_3</th>\n",
       "      <th>robotic_circuits_speed_4</th>\n",
       "      <th>robotic_circuits_speed_5</th>\n",
       "      <th>robotic_circuits_speed_6</th>\n",
       "      <th>robotic_circuits_speed_12</th>\n",
       "      <th>robot_engine_speed_13</th>\n",
       "      <th>robot_engine_speed_14</th>\n",
       "      <th>robot_engine_speed_15</th>\n",
       "      <th>robot_engine_speed_16</th>\n",
       "      <th>robot_engine_circulation_2</th>\n",
       "      <th>robot_engine_circulation_3</th>\n",
       "      <th>robot_engine_circulation_4</th>\n",
       "      <th>robot_engine_circulation_6</th>\n",
       "      <th>robot_engine_circulation_7</th>\n",
       "      <th>robot_engine_circulation_8</th>\n",
       "      <th>robot_engine_ground_1</th>\n",
       "      <th>robot_engine_compression_1</th>\n",
       "      <th>robot_engine_compression_2</th>\n",
       "      <th>robot_engine_compression_3</th>\n",
       "      <th>weapon_robot_eye_laser_emission_2</th>\n",
       "      <th>robot_engine_temperature_2</th>\n",
       "      <th>robot_engine_temperature_3</th>\n",
       "      <th>robot_engine_temperature_4</th>\n",
       "      <th>robot_engine_temperature_5</th>\n",
       "      <th>robot_engine_temperature_6</th>\n",
       "      <th>weapon_robot_eye_laser_sensor_2</th>\n",
       "      <th>weapon_robot_punch_left_1</th>\n",
       "      <th>robot_engine_temperature_9</th>\n",
       "      <th>robot_engine_temperature_10</th>\n",
       "      <th>robot_engine_temperature_11</th>\n",
       "      <th>robot_engine_temperature_12</th>\n",
       "      <th>robot_engine_temperature_13</th>\n",
       "      <th>robot_engine_temperature_14</th>\n",
       "      <th>robot_engine_temperature_15</th>\n",
       "      <th>robot_engine_temperature_16</th>\n",
       "      <th>robot_engine_temperature_17</th>\n",
       "      <th>weapon_robot_eye_laser_range_2</th>\n",
       "      <th>weapon_robot_eye_laser_sensor_3</th>\n",
       "      <th>robot_engine_temperature_20</th>\n",
       "      <th>robot_engine_temperature_21</th>\n",
       "      <th>weapon_robot_eye_laser_emission_3</th>\n",
       "      <th>robot_engine_temperature_23</th>\n",
       "      <th>robot_engine_temperature_24</th>\n",
       "      <th>robot_engine_temperature_25</th>\n",
       "      <th>robot_engine_temperature_26</th>\n",
       "      <th>robot_engine_temperature_27</th>\n",
       "      <th>robot_engine_temperature_28</th>\n",
       "      <th>robot_probe_compression_diff_1</th>\n",
       "      <th>robot_probe_compression_diff_2</th>\n",
       "      <th>robot_probe_compression_diff_3</th>\n",
       "      <th>robot_probe_compression_diff_4</th>\n",
       "      <th>robot_probe_compression_diff_5</th>\n",
       "      <th>robot_probe_compression_diff_6</th>\n",
       "      <th>robot_probe_compression_diff_7</th>\n",
       "      <th>robot_probe_compression_diff_8</th>\n",
       "      <th>robot_probe_compression_diff_9</th>\n",
       "      <th>robot_probe_compression_diff_10</th>\n",
       "      <th>robot_probe_circulation_1</th>\n",
       "      <th>robot_probe_circulation_2</th>\n",
       "      <th>robot_probe_circulation_3</th>\n",
       "      <th>robot_probe_circulation_4</th>\n",
       "      <th>robot_probe_circulation_5</th>\n",
       "      <th>robot_probe_circulation_6</th>\n",
       "      <th>robot_probe_circulation_7</th>\n",
       "      <th>weapon_robot_armour_index_1</th>\n",
       "      <th>robot_probe_circulation_9</th>\n",
       "      <th>robot_probe_circulation_10</th>\n",
       "      <th>robot_probe_circulation_11</th>\n",
       "      <th>robot_probe_circulation_12</th>\n",
       "      <th>robot_probe_temperature_1</th>\n",
       "      <th>robot_probe_temperature_2</th>\n",
       "      <th>robot_probe_temperature_3</th>\n",
       "      <th>weapon_robot_eye_laser_sensor_4</th>\n",
       "      <th>robot_probe_temperature_5</th>\n",
       "      <th>robot_probe_temperature_6</th>\n",
       "      <th>robot_probe_temperature_7</th>\n",
       "      <th>robot_probe_temperature_8</th>\n",
       "      <th>robot_probe_temperature_9</th>\n",
       "      <th>weapon_robot_eye_laser_range_1</th>\n",
       "      <th>weapon_robot_punch_left_4</th>\n",
       "      <th>weapon_robot_punch_left_2</th>\n",
       "      <th>gamma_ray</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.022325</td>\n",
       "      <td>13.997181</td>\n",
       "      <td>15.184937</td>\n",
       "      <td>9.143568</td>\n",
       "      <td>16.518011</td>\n",
       "      <td>11.032224</td>\n",
       "      <td>19.134443</td>\n",
       "      <td>12.103030</td>\n",
       "      <td>-16.814669</td>\n",
       "      <td>21.295624</td>\n",
       "      <td>8.248064</td>\n",
       "      <td>23.816521</td>\n",
       "      <td>26.244662</td>\n",
       "      <td>46.417894</td>\n",
       "      <td>44.887274</td>\n",
       "      <td>39.005165</td>\n",
       "      <td>11.615466</td>\n",
       "      <td>34.499397</td>\n",
       "      <td>37.145391</td>\n",
       "      <td>47.885525</td>\n",
       "      <td>2.603021</td>\n",
       "      <td>-6.184393</td>\n",
       "      <td>9.820208</td>\n",
       "      <td>1.334567</td>\n",
       "      <td>1.185980</td>\n",
       "      <td>0.859691</td>\n",
       "      <td>14.136915</td>\n",
       "      <td>38.622189</td>\n",
       "      <td>-14.975311</td>\n",
       "      <td>-12.978151</td>\n",
       "      <td>4.616656</td>\n",
       "      <td>13.187774</td>\n",
       "      <td>3.284418</td>\n",
       "      <td>54.703483</td>\n",
       "      <td>16.243180</td>\n",
       "      <td>12.115450</td>\n",
       "      <td>26.324291</td>\n",
       "      <td>45.596036</td>\n",
       "      <td>58.847889</td>\n",
       "      <td>73.652303</td>\n",
       "      <td>-3.795967</td>\n",
       "      <td>-7.464172</td>\n",
       "      <td>-3.671964</td>\n",
       "      <td>-3.364944</td>\n",
       "      <td>6.576776</td>\n",
       "      <td>0.527796</td>\n",
       "      <td>4.504332</td>\n",
       "      <td>-2.169179</td>\n",
       "      <td>7.187517</td>\n",
       "      <td>12.825287</td>\n",
       "      <td>4.953914</td>\n",
       "      <td>1.983918</td>\n",
       "      <td>3.194329</td>\n",
       "      <td>4.484886</td>\n",
       "      <td>3.503567</td>\n",
       "      <td>1.217541</td>\n",
       "      <td>2.520359</td>\n",
       "      <td>9.370190</td>\n",
       "      <td>-5.077781</td>\n",
       "      <td>-17.503432</td>\n",
       "      <td>-10.215661</td>\n",
       "      <td>-4.630866</td>\n",
       "      <td>28.853486</td>\n",
       "      <td>14.273299</td>\n",
       "      <td>-2.161208</td>\n",
       "      <td>46.713815</td>\n",
       "      <td>-2.885696</td>\n",
       "      <td>-38.312932</td>\n",
       "      <td>-11.446719</td>\n",
       "      <td>-0.474725</td>\n",
       "      <td>5.363054</td>\n",
       "      <td>-3.798114</td>\n",
       "      <td>-0.181042</td>\n",
       "      <td>150.228380</td>\n",
       "      <td>-0.784865</td>\n",
       "      <td>3.447505</td>\n",
       "      <td>10.732660</td>\n",
       "      <td>-36.664788</td>\n",
       "      <td>-10.473782</td>\n",
       "      <td>6.104714</td>\n",
       "      <td>5.830890</td>\n",
       "      <td>7.049742</td>\n",
       "      <td>1.807148</td>\n",
       "      <td>-13.320545</td>\n",
       "      <td>4.490204</td>\n",
       "      <td>-10.704910</td>\n",
       "      <td>9.186453</td>\n",
       "      <td>2.635537</td>\n",
       "      <td>4.790467</td>\n",
       "      <td>10.816384</td>\n",
       "      <td>31.909540</td>\n",
       "      <td>34.048861</td>\n",
       "      <td>10.708144</td>\n",
       "      <td>20.777292</td>\n",
       "      <td>18.288897</td>\n",
       "      <td>16.109053</td>\n",
       "      <td>14.557100</td>\n",
       "      <td>19.780202</td>\n",
       "      <td>8.367372</td>\n",
       "      <td>0.445303</td>\n",
       "      <td>-4.015652</td>\n",
       "      <td>2.429023</td>\n",
       "      <td>-6.412623</td>\n",
       "      <td>15.063743</td>\n",
       "      <td>8.872546</td>\n",
       "      <td>3.042562</td>\n",
       "      <td>7.971202</td>\n",
       "      <td>10.391109</td>\n",
       "      <td>-25.532159</td>\n",
       "      <td>-9.138703</td>\n",
       "      <td>27.144017</td>\n",
       "      <td>13.329794</td>\n",
       "      <td>36.887150</td>\n",
       "      <td>6.828675</td>\n",
       "      <td>2.566964</td>\n",
       "      <td>22.155350</td>\n",
       "      <td>4.568011</td>\n",
       "      <td>-3.958901</td>\n",
       "      <td>-18.443393</td>\n",
       "      <td>-27.024871</td>\n",
       "      <td>1.034110</td>\n",
       "      <td>29.591594</td>\n",
       "      <td>-28.428208</td>\n",
       "      <td>3.079533</td>\n",
       "      <td>2.801983</td>\n",
       "      <td>2.246083</td>\n",
       "      <td>0.703428</td>\n",
       "      <td>0.524766</td>\n",
       "      <td>1.093207</td>\n",
       "      <td>1.851268</td>\n",
       "      <td>-1.418870</td>\n",
       "      <td>-19.416280</td>\n",
       "      <td>4.024151</td>\n",
       "      <td>-29.258844</td>\n",
       "      <td>0.956559</td>\n",
       "      <td>4.313994</td>\n",
       "      <td>2.224619</td>\n",
       "      <td>1.707880</td>\n",
       "      <td>3.312073</td>\n",
       "      <td>1.880423</td>\n",
       "      <td>1.398944</td>\n",
       "      <td>-5.435478</td>\n",
       "      <td>-19.428795</td>\n",
       "      <td>moderate</td>\n",
       "      <td>15.397337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.197158</td>\n",
       "      <td>-10.670913</td>\n",
       "      <td>-10.702876</td>\n",
       "      <td>-4.174599</td>\n",
       "      <td>-27.779796</td>\n",
       "      <td>-6.880274</td>\n",
       "      <td>-14.636978</td>\n",
       "      <td>-7.739600</td>\n",
       "      <td>11.369873</td>\n",
       "      <td>-18.888534</td>\n",
       "      <td>-3.077153</td>\n",
       "      <td>-35.756743</td>\n",
       "      <td>-7.890201</td>\n",
       "      <td>-32.342056</td>\n",
       "      <td>-30.077172</td>\n",
       "      <td>-26.674804</td>\n",
       "      <td>-6.180791</td>\n",
       "      <td>-15.913001</td>\n",
       "      <td>-21.043362</td>\n",
       "      <td>-28.003142</td>\n",
       "      <td>-7.095076</td>\n",
       "      <td>-6.188305</td>\n",
       "      <td>9.776913</td>\n",
       "      <td>2.406217</td>\n",
       "      <td>0.951175</td>\n",
       "      <td>0.743346</td>\n",
       "      <td>-10.058164</td>\n",
       "      <td>-24.541176</td>\n",
       "      <td>6.679249</td>\n",
       "      <td>-13.999818</td>\n",
       "      <td>4.423905</td>\n",
       "      <td>13.568875</td>\n",
       "      <td>-1.173119</td>\n",
       "      <td>-15.719489</td>\n",
       "      <td>-9.608472</td>\n",
       "      <td>-8.260229</td>\n",
       "      <td>-15.431824</td>\n",
       "      <td>-26.936311</td>\n",
       "      <td>-27.585389</td>\n",
       "      <td>-15.170800</td>\n",
       "      <td>11.474089</td>\n",
       "      <td>8.229660</td>\n",
       "      <td>6.082031</td>\n",
       "      <td>5.167638</td>\n",
       "      <td>-16.721847</td>\n",
       "      <td>-16.186060</td>\n",
       "      <td>11.251515</td>\n",
       "      <td>6.637927</td>\n",
       "      <td>-1.061704</td>\n",
       "      <td>-2.147483</td>\n",
       "      <td>-0.722372</td>\n",
       "      <td>3.145395</td>\n",
       "      <td>-0.319032</td>\n",
       "      <td>1.476939</td>\n",
       "      <td>0.539965</td>\n",
       "      <td>1.356178</td>\n",
       "      <td>2.289875</td>\n",
       "      <td>3.914182</td>\n",
       "      <td>-9.558711</td>\n",
       "      <td>-22.135869</td>\n",
       "      <td>43.530939</td>\n",
       "      <td>29.616915</td>\n",
       "      <td>-19.339158</td>\n",
       "      <td>-3.941162</td>\n",
       "      <td>-2.161208</td>\n",
       "      <td>-28.988268</td>\n",
       "      <td>-2.885696</td>\n",
       "      <td>4.638579</td>\n",
       "      <td>-0.251091</td>\n",
       "      <td>-0.657708</td>\n",
       "      <td>-2.235007</td>\n",
       "      <td>-3.798114</td>\n",
       "      <td>-0.181042</td>\n",
       "      <td>-6.640280</td>\n",
       "      <td>-0.784865</td>\n",
       "      <td>3.348375</td>\n",
       "      <td>5.912657</td>\n",
       "      <td>-67.824152</td>\n",
       "      <td>9.031702</td>\n",
       "      <td>-23.273579</td>\n",
       "      <td>1.453058</td>\n",
       "      <td>4.189286</td>\n",
       "      <td>7.152650</td>\n",
       "      <td>-5.068283</td>\n",
       "      <td>-16.584261</td>\n",
       "      <td>-25.082848</td>\n",
       "      <td>3.399787</td>\n",
       "      <td>2.061354</td>\n",
       "      <td>32.354666</td>\n",
       "      <td>14.552372</td>\n",
       "      <td>26.706567</td>\n",
       "      <td>19.121773</td>\n",
       "      <td>5.000758</td>\n",
       "      <td>8.330831</td>\n",
       "      <td>8.522225</td>\n",
       "      <td>9.469023</td>\n",
       "      <td>8.633386</td>\n",
       "      <td>11.747068</td>\n",
       "      <td>5.237374</td>\n",
       "      <td>5.245968</td>\n",
       "      <td>15.348407</td>\n",
       "      <td>9.690732</td>\n",
       "      <td>6.818751</td>\n",
       "      <td>12.247220</td>\n",
       "      <td>7.948006</td>\n",
       "      <td>20.834549</td>\n",
       "      <td>7.217812</td>\n",
       "      <td>15.011473</td>\n",
       "      <td>37.056865</td>\n",
       "      <td>26.756684</td>\n",
       "      <td>-26.022117</td>\n",
       "      <td>-26.863387</td>\n",
       "      <td>-21.325012</td>\n",
       "      <td>-8.087737</td>\n",
       "      <td>18.723787</td>\n",
       "      <td>-41.379219</td>\n",
       "      <td>-15.064479</td>\n",
       "      <td>-1.087822</td>\n",
       "      <td>-7.705042</td>\n",
       "      <td>-17.296723</td>\n",
       "      <td>1.810793</td>\n",
       "      <td>-0.773743</td>\n",
       "      <td>26.996366</td>\n",
       "      <td>22.956582</td>\n",
       "      <td>1.796040</td>\n",
       "      <td>1.362588</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>0.554393</td>\n",
       "      <td>1.339379</td>\n",
       "      <td>1.621164</td>\n",
       "      <td>3.266927</td>\n",
       "      <td>14.502751</td>\n",
       "      <td>1.867720</td>\n",
       "      <td>0.794318</td>\n",
       "      <td>1.242203</td>\n",
       "      <td>7.379914</td>\n",
       "      <td>5.653545</td>\n",
       "      <td>0.543057</td>\n",
       "      <td>2.893023</td>\n",
       "      <td>0.988734</td>\n",
       "      <td>0.819479</td>\n",
       "      <td>11.373292</td>\n",
       "      <td>-9.819610</td>\n",
       "      <td>high</td>\n",
       "      <td>-7.317431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241552</td>\n",
       "      <td>-0.590521</td>\n",
       "      <td>-0.429871</td>\n",
       "      <td>8.692113</td>\n",
       "      <td>-12.025083</td>\n",
       "      <td>0.505531</td>\n",
       "      <td>-0.659359</td>\n",
       "      <td>-0.395109</td>\n",
       "      <td>7.809366</td>\n",
       "      <td>-0.909444</td>\n",
       "      <td>7.381037</td>\n",
       "      <td>-50.973295</td>\n",
       "      <td>59.105901</td>\n",
       "      <td>-3.747991</td>\n",
       "      <td>-4.094140</td>\n",
       "      <td>-3.136346</td>\n",
       "      <td>-0.043320</td>\n",
       "      <td>-2.697588</td>\n",
       "      <td>-1.135222</td>\n",
       "      <td>-0.635100</td>\n",
       "      <td>-9.372386</td>\n",
       "      <td>-6.190795</td>\n",
       "      <td>9.946887</td>\n",
       "      <td>2.339053</td>\n",
       "      <td>0.958831</td>\n",
       "      <td>0.898652</td>\n",
       "      <td>-1.186339</td>\n",
       "      <td>-20.847688</td>\n",
       "      <td>-14.390821</td>\n",
       "      <td>-11.716950</td>\n",
       "      <td>4.122897</td>\n",
       "      <td>14.019858</td>\n",
       "      <td>-1.775460</td>\n",
       "      <td>-21.254197</td>\n",
       "      <td>0.919152</td>\n",
       "      <td>-0.404784</td>\n",
       "      <td>-0.658352</td>\n",
       "      <td>-1.427301</td>\n",
       "      <td>-5.666960</td>\n",
       "      <td>-19.341990</td>\n",
       "      <td>-3.680370</td>\n",
       "      <td>9.157112</td>\n",
       "      <td>2.663821</td>\n",
       "      <td>4.406640</td>\n",
       "      <td>1.738250</td>\n",
       "      <td>0.541970</td>\n",
       "      <td>8.678612</td>\n",
       "      <td>14.591514</td>\n",
       "      <td>13.098520</td>\n",
       "      <td>14.463979</td>\n",
       "      <td>3.258806</td>\n",
       "      <td>1.815922</td>\n",
       "      <td>1.410845</td>\n",
       "      <td>3.386619</td>\n",
       "      <td>1.744569</td>\n",
       "      <td>1.371464</td>\n",
       "      <td>3.045223</td>\n",
       "      <td>4.355896</td>\n",
       "      <td>-11.464096</td>\n",
       "      <td>-17.383628</td>\n",
       "      <td>-15.762626</td>\n",
       "      <td>36.202119</td>\n",
       "      <td>-11.738481</td>\n",
       "      <td>9.836011</td>\n",
       "      <td>0.818537</td>\n",
       "      <td>-9.755374</td>\n",
       "      <td>-2.885696</td>\n",
       "      <td>6.824468</td>\n",
       "      <td>88.535434</td>\n",
       "      <td>-0.479923</td>\n",
       "      <td>-0.904454</td>\n",
       "      <td>-3.798114</td>\n",
       "      <td>-0.181042</td>\n",
       "      <td>-21.794122</td>\n",
       "      <td>-0.784865</td>\n",
       "      <td>3.500581</td>\n",
       "      <td>13.153222</td>\n",
       "      <td>120.548244</td>\n",
       "      <td>4.024159</td>\n",
       "      <td>4.214334</td>\n",
       "      <td>6.781774</td>\n",
       "      <td>1.309586</td>\n",
       "      <td>1.913895</td>\n",
       "      <td>-12.053524</td>\n",
       "      <td>-3.944695</td>\n",
       "      <td>-23.962949</td>\n",
       "      <td>7.174653</td>\n",
       "      <td>1.924248</td>\n",
       "      <td>-6.323375</td>\n",
       "      <td>3.518100</td>\n",
       "      <td>10.531036</td>\n",
       "      <td>16.206847</td>\n",
       "      <td>5.423623</td>\n",
       "      <td>11.868446</td>\n",
       "      <td>12.080818</td>\n",
       "      <td>12.583103</td>\n",
       "      <td>11.451579</td>\n",
       "      <td>16.591783</td>\n",
       "      <td>7.947888</td>\n",
       "      <td>6.146104</td>\n",
       "      <td>11.414823</td>\n",
       "      <td>2.280832</td>\n",
       "      <td>2.438626</td>\n",
       "      <td>0.978467</td>\n",
       "      <td>-2.224259</td>\n",
       "      <td>3.042562</td>\n",
       "      <td>6.519839</td>\n",
       "      <td>12.239002</td>\n",
       "      <td>-4.669151</td>\n",
       "      <td>4.791272</td>\n",
       "      <td>-0.821454</td>\n",
       "      <td>-2.777764</td>\n",
       "      <td>26.003488</td>\n",
       "      <td>0.590067</td>\n",
       "      <td>11.976170</td>\n",
       "      <td>-0.116564</td>\n",
       "      <td>7.873736</td>\n",
       "      <td>24.267985</td>\n",
       "      <td>123.941232</td>\n",
       "      <td>-24.506704</td>\n",
       "      <td>1.711940</td>\n",
       "      <td>-0.962896</td>\n",
       "      <td>14.775838</td>\n",
       "      <td>8.946374</td>\n",
       "      <td>1.057677</td>\n",
       "      <td>1.693853</td>\n",
       "      <td>0.313653</td>\n",
       "      <td>0.602489</td>\n",
       "      <td>1.488056</td>\n",
       "      <td>1.170048</td>\n",
       "      <td>3.252794</td>\n",
       "      <td>10.006982</td>\n",
       "      <td>1.867720</td>\n",
       "      <td>1.849255</td>\n",
       "      <td>0.242597</td>\n",
       "      <td>1.758199</td>\n",
       "      <td>3.239786</td>\n",
       "      <td>0.632581</td>\n",
       "      <td>3.057811</td>\n",
       "      <td>2.043147</td>\n",
       "      <td>1.671686</td>\n",
       "      <td>8.493152</td>\n",
       "      <td>1.261253</td>\n",
       "      <td>high</td>\n",
       "      <td>5.401647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.557153</td>\n",
       "      <td>14.435547</td>\n",
       "      <td>14.506505</td>\n",
       "      <td>5.889579</td>\n",
       "      <td>20.158102</td>\n",
       "      <td>11.622649</td>\n",
       "      <td>20.503707</td>\n",
       "      <td>17.262173</td>\n",
       "      <td>-22.620158</td>\n",
       "      <td>25.909849</td>\n",
       "      <td>13.856295</td>\n",
       "      <td>21.396236</td>\n",
       "      <td>37.709597</td>\n",
       "      <td>46.836409</td>\n",
       "      <td>45.417368</td>\n",
       "      <td>39.449591</td>\n",
       "      <td>13.136138</td>\n",
       "      <td>39.497465</td>\n",
       "      <td>41.948916</td>\n",
       "      <td>52.483156</td>\n",
       "      <td>-6.295341</td>\n",
       "      <td>-6.189141</td>\n",
       "      <td>9.768772</td>\n",
       "      <td>1.182926</td>\n",
       "      <td>1.031191</td>\n",
       "      <td>0.903637</td>\n",
       "      <td>14.074106</td>\n",
       "      <td>39.170796</td>\n",
       "      <td>-15.496568</td>\n",
       "      <td>-13.585472</td>\n",
       "      <td>4.156537</td>\n",
       "      <td>14.407907</td>\n",
       "      <td>3.792095</td>\n",
       "      <td>28.103502</td>\n",
       "      <td>16.080564</td>\n",
       "      <td>12.947821</td>\n",
       "      <td>27.305680</td>\n",
       "      <td>47.308153</td>\n",
       "      <td>63.762221</td>\n",
       "      <td>78.907900</td>\n",
       "      <td>-4.285083</td>\n",
       "      <td>-9.236130</td>\n",
       "      <td>0.209753</td>\n",
       "      <td>-1.703373</td>\n",
       "      <td>-17.783190</td>\n",
       "      <td>-9.103903</td>\n",
       "      <td>1.793981</td>\n",
       "      <td>-3.830587</td>\n",
       "      <td>6.758048</td>\n",
       "      <td>11.946038</td>\n",
       "      <td>7.209061</td>\n",
       "      <td>3.844475</td>\n",
       "      <td>3.685869</td>\n",
       "      <td>7.353406</td>\n",
       "      <td>4.644027</td>\n",
       "      <td>1.689243</td>\n",
       "      <td>4.531766</td>\n",
       "      <td>5.420151</td>\n",
       "      <td>-40.328406</td>\n",
       "      <td>-17.530055</td>\n",
       "      <td>-15.537264</td>\n",
       "      <td>2.895318</td>\n",
       "      <td>16.165523</td>\n",
       "      <td>16.807930</td>\n",
       "      <td>-2.161208</td>\n",
       "      <td>45.997424</td>\n",
       "      <td>-2.885696</td>\n",
       "      <td>-38.275813</td>\n",
       "      <td>-56.871247</td>\n",
       "      <td>-0.713055</td>\n",
       "      <td>5.124459</td>\n",
       "      <td>-3.798114</td>\n",
       "      <td>-0.181042</td>\n",
       "      <td>52.801194</td>\n",
       "      <td>-0.784865</td>\n",
       "      <td>3.352952</td>\n",
       "      <td>9.187708</td>\n",
       "      <td>-40.179388</td>\n",
       "      <td>-15.069542</td>\n",
       "      <td>-3.615632</td>\n",
       "      <td>0.594819</td>\n",
       "      <td>-13.001091</td>\n",
       "      <td>-25.073984</td>\n",
       "      <td>-21.073792</td>\n",
       "      <td>-101.343587</td>\n",
       "      <td>-43.436807</td>\n",
       "      <td>-11.055757</td>\n",
       "      <td>0.730160</td>\n",
       "      <td>16.131223</td>\n",
       "      <td>6.771540</td>\n",
       "      <td>13.093845</td>\n",
       "      <td>1.951375</td>\n",
       "      <td>-0.001606</td>\n",
       "      <td>-4.514685</td>\n",
       "      <td>-5.682675</td>\n",
       "      <td>-11.592715</td>\n",
       "      <td>-9.653606</td>\n",
       "      <td>-15.423589</td>\n",
       "      <td>-7.501322</td>\n",
       "      <td>-2.855071</td>\n",
       "      <td>-0.649851</td>\n",
       "      <td>8.981873</td>\n",
       "      <td>2.834283</td>\n",
       "      <td>12.247220</td>\n",
       "      <td>16.270027</td>\n",
       "      <td>22.614532</td>\n",
       "      <td>-3.798134</td>\n",
       "      <td>-10.862817</td>\n",
       "      <td>-13.013215</td>\n",
       "      <td>4.647612</td>\n",
       "      <td>-5.016823</td>\n",
       "      <td>-11.392007</td>\n",
       "      <td>-4.866177</td>\n",
       "      <td>3.574090</td>\n",
       "      <td>-12.833071</td>\n",
       "      <td>-0.675685</td>\n",
       "      <td>11.230330</td>\n",
       "      <td>-2.304156</td>\n",
       "      <td>-13.048415</td>\n",
       "      <td>-5.505190</td>\n",
       "      <td>0.686010</td>\n",
       "      <td>18.801734</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>-0.095807</td>\n",
       "      <td>2.649294</td>\n",
       "      <td>0.195881</td>\n",
       "      <td>0.963933</td>\n",
       "      <td>0.490999</td>\n",
       "      <td>1.644450</td>\n",
       "      <td>0.886139</td>\n",
       "      <td>12.287236</td>\n",
       "      <td>-18.912198</td>\n",
       "      <td>3.065810</td>\n",
       "      <td>-38.674593</td>\n",
       "      <td>0.385419</td>\n",
       "      <td>-3.325947</td>\n",
       "      <td>-6.368580</td>\n",
       "      <td>2.111040</td>\n",
       "      <td>3.197349</td>\n",
       "      <td>2.086597</td>\n",
       "      <td>1.809794</td>\n",
       "      <td>-12.245653</td>\n",
       "      <td>3.477425</td>\n",
       "      <td>low</td>\n",
       "      <td>14.776876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.511287</td>\n",
       "      <td>14.511120</td>\n",
       "      <td>16.457464</td>\n",
       "      <td>30.010935</td>\n",
       "      <td>15.408536</td>\n",
       "      <td>12.459168</td>\n",
       "      <td>15.919603</td>\n",
       "      <td>14.963951</td>\n",
       "      <td>10.379404</td>\n",
       "      <td>21.603598</td>\n",
       "      <td>14.663186</td>\n",
       "      <td>12.715192</td>\n",
       "      <td>51.392658</td>\n",
       "      <td>47.326230</td>\n",
       "      <td>47.202218</td>\n",
       "      <td>40.609520</td>\n",
       "      <td>8.950382</td>\n",
       "      <td>27.126314</td>\n",
       "      <td>28.704554</td>\n",
       "      <td>40.752719</td>\n",
       "      <td>-1.670670</td>\n",
       "      <td>-6.185109</td>\n",
       "      <td>9.997210</td>\n",
       "      <td>2.151075</td>\n",
       "      <td>1.128960</td>\n",
       "      <td>0.897534</td>\n",
       "      <td>14.236896</td>\n",
       "      <td>43.036403</td>\n",
       "      <td>-14.761800</td>\n",
       "      <td>-14.350428</td>\n",
       "      <td>4.200700</td>\n",
       "      <td>13.652021</td>\n",
       "      <td>-1.724839</td>\n",
       "      <td>-13.387344</td>\n",
       "      <td>16.913843</td>\n",
       "      <td>12.705062</td>\n",
       "      <td>27.685544</td>\n",
       "      <td>47.434716</td>\n",
       "      <td>62.963577</td>\n",
       "      <td>89.607245</td>\n",
       "      <td>-1.790087</td>\n",
       "      <td>-7.373313</td>\n",
       "      <td>-2.098241</td>\n",
       "      <td>-1.629350</td>\n",
       "      <td>-25.353197</td>\n",
       "      <td>-16.655035</td>\n",
       "      <td>3.171688</td>\n",
       "      <td>0.747609</td>\n",
       "      <td>12.434741</td>\n",
       "      <td>11.822082</td>\n",
       "      <td>5.751024</td>\n",
       "      <td>2.303356</td>\n",
       "      <td>2.628652</td>\n",
       "      <td>4.156034</td>\n",
       "      <td>2.653597</td>\n",
       "      <td>0.753482</td>\n",
       "      <td>1.812826</td>\n",
       "      <td>5.764022</td>\n",
       "      <td>-41.627416</td>\n",
       "      <td>-19.637091</td>\n",
       "      <td>-36.504345</td>\n",
       "      <td>-22.756574</td>\n",
       "      <td>32.936785</td>\n",
       "      <td>21.447256</td>\n",
       "      <td>-2.161208</td>\n",
       "      <td>64.809931</td>\n",
       "      <td>-2.885696</td>\n",
       "      <td>4.063702</td>\n",
       "      <td>-7.777472</td>\n",
       "      <td>-0.680316</td>\n",
       "      <td>-1.965311</td>\n",
       "      <td>-3.798114</td>\n",
       "      <td>5.651547</td>\n",
       "      <td>-15.391090</td>\n",
       "      <td>-0.784865</td>\n",
       "      <td>4.365232</td>\n",
       "      <td>12.418677</td>\n",
       "      <td>-32.889019</td>\n",
       "      <td>-0.444314</td>\n",
       "      <td>42.429364</td>\n",
       "      <td>3.264907</td>\n",
       "      <td>3.769403</td>\n",
       "      <td>8.065280</td>\n",
       "      <td>-9.259975</td>\n",
       "      <td>0.736611</td>\n",
       "      <td>-17.855858</td>\n",
       "      <td>5.511079</td>\n",
       "      <td>2.057259</td>\n",
       "      <td>-2.110580</td>\n",
       "      <td>4.670925</td>\n",
       "      <td>10.934897</td>\n",
       "      <td>13.045087</td>\n",
       "      <td>4.696812</td>\n",
       "      <td>8.949077</td>\n",
       "      <td>10.626095</td>\n",
       "      <td>9.819817</td>\n",
       "      <td>10.282914</td>\n",
       "      <td>14.282582</td>\n",
       "      <td>6.517787</td>\n",
       "      <td>1.945404</td>\n",
       "      <td>0.556648</td>\n",
       "      <td>-1.325951</td>\n",
       "      <td>-2.836211</td>\n",
       "      <td>5.204139</td>\n",
       "      <td>-2.224259</td>\n",
       "      <td>-7.632855</td>\n",
       "      <td>5.840904</td>\n",
       "      <td>9.467163</td>\n",
       "      <td>12.018977</td>\n",
       "      <td>-8.238066</td>\n",
       "      <td>11.928785</td>\n",
       "      <td>13.358453</td>\n",
       "      <td>-25.132700</td>\n",
       "      <td>10.666568</td>\n",
       "      <td>1.111177</td>\n",
       "      <td>-32.429802</td>\n",
       "      <td>11.926406</td>\n",
       "      <td>-7.662478</td>\n",
       "      <td>3.328816</td>\n",
       "      <td>-23.318567</td>\n",
       "      <td>1.670394</td>\n",
       "      <td>25.583845</td>\n",
       "      <td>-16.773806</td>\n",
       "      <td>10.792678</td>\n",
       "      <td>2.698143</td>\n",
       "      <td>1.476792</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.727938</td>\n",
       "      <td>1.623572</td>\n",
       "      <td>1.474556</td>\n",
       "      <td>3.255436</td>\n",
       "      <td>-18.645137</td>\n",
       "      <td>-0.768209</td>\n",
       "      <td>42.770926</td>\n",
       "      <td>0.385419</td>\n",
       "      <td>2.748025</td>\n",
       "      <td>4.692944</td>\n",
       "      <td>-0.749481</td>\n",
       "      <td>2.930634</td>\n",
       "      <td>1.006564</td>\n",
       "      <td>1.951764</td>\n",
       "      <td>-9.711888</td>\n",
       "      <td>-14.148072</td>\n",
       "      <td>moderate</td>\n",
       "      <td>16.706581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   robot_gear_compression_diff_1  weapon_robot_armour_index_2  robot_gear_compression_diff_3    ...      weapon_robot_punch_left_2  gamma_ray     target\n",
       "0                      14.022325                    13.997181                      15.184937    ...                     -19.428795   moderate  15.397337\n",
       "1                      -9.197158                   -10.670913                     -10.702876    ...                      -9.819610       high  -7.317431\n",
       "2                       0.241552                    -0.590521                      -0.429871    ...                       1.261253       high   5.401647\n",
       "3                      14.557153                    14.435547                      14.506505    ...                       3.477425        low  14.776876\n",
       "4                      14.511287                    14.511120                      16.457464    ...                     -14.148072   moderate  16.706581\n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train mlp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создавать все модели меняя эту функцию не самая лучшая идея, поэтому когда делаете новую модель лучше всего написать новую функцию аналагичную этой (да и вообще лучше целую секцию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_cols):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, activation='relu', input_shape=(n_cols,), kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2 metric \n",
    "\n",
    "${R^2 = \\frac{\\sum{(y_i - \\hat{y_i})^2}}{\\sum{(y_i - \\bar{y})^2}}}$\n",
    "\n",
    "${\\hat{y_i}}$ -- предсказанное значение \n",
    "${\\bar{y}}$ -- среднее значение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               18560     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 249,217\n",
      "Trainable params: 249,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(df, 600, 'simple')\n",
    "\n",
    "verbose = 0 # выводить ли инфу в процессе обучения (на гитхаб лучше не заливать когда verbose > 0, а просто перетренировать с = 0, ну или если это долго то перед комитом очистить оутпуты)\n",
    "            # 0 - silence \n",
    "            # 1 - progress bar\n",
    "            # 2 - line per epoch \n",
    "model = create_model(X_train.shape[1])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[coeff_determination])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=400, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся инфа про обучение лежит в history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9684065508797737,\n",
       " 0.9692448909913398,\n",
       " 0.9688925257766895,\n",
       " 0.9676088335142797,\n",
       " 0.9649802704689426,\n",
       " 0.9655745160288927,\n",
       " 0.96018564566886,\n",
       " 0.9658777722721923,\n",
       " 0.956757009141217,\n",
       " 0.9672592929782832]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_coeff_determination'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.663284142812093, 0.9770452308654786]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 940, 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submition(model, subm_name='subm_mlp_250k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_full_set(enc='simple', create_model=create_model, epochs=400, verbose=0):\n",
    "    dataset = pd.read_csv('./robot_data/train_data.csv')    \n",
    "    dataset = dataset.drop(columns=['year'])\n",
    "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    X_train, y_train, X_test, y_test = split_train_test(dataset, 0, enc)\n",
    "    model = create_model(X_train.shape[1])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[coeff_determination])\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, verbose=verbose)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_full_set()\n",
    "\n",
    "#model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try learn not only nn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    DecisionTreeRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    GradientBoostingRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./robot_data/train_data.csv') \n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "скейлим датасет и сопоставляем значения категориям "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>robot_gear_compression_diff_1</th>\n",
       "      <th>weapon_robot_armour_index_2</th>\n",
       "      <th>robot_gear_compression_diff_3</th>\n",
       "      <th>robot_gear_compression_diff_4</th>\n",
       "      <th>weapon_robot_punch_right_1</th>\n",
       "      <th>robot_gear_compression_diff_6</th>\n",
       "      <th>robot_gear_compression_diff_7</th>\n",
       "      <th>robot_gear_compression_diff_8</th>\n",
       "      <th>robot_gear_compression_diff_9</th>\n",
       "      <th>...</th>\n",
       "      <th>robot_probe_temperature_5</th>\n",
       "      <th>robot_probe_temperature_6</th>\n",
       "      <th>robot_probe_temperature_7</th>\n",
       "      <th>robot_probe_temperature_8</th>\n",
       "      <th>robot_probe_temperature_9</th>\n",
       "      <th>weapon_robot_eye_laser_range_1</th>\n",
       "      <th>weapon_robot_punch_left_4</th>\n",
       "      <th>weapon_robot_punch_left_2</th>\n",
       "      <th>gamma_ray</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3777</td>\n",
       "      <td>13.493252</td>\n",
       "      <td>13.203419</td>\n",
       "      <td>15.945541</td>\n",
       "      <td>35.322252</td>\n",
       "      <td>18.592792</td>\n",
       "      <td>11.956559</td>\n",
       "      <td>17.916364</td>\n",
       "      <td>17.653934</td>\n",
       "      <td>29.217912</td>\n",
       "      <td>...</td>\n",
       "      <td>2.887527</td>\n",
       "      <td>3.375930</td>\n",
       "      <td>-3.963133</td>\n",
       "      <td>2.921440</td>\n",
       "      <td>2.784923</td>\n",
       "      <td>1.625606</td>\n",
       "      <td>-0.647793</td>\n",
       "      <td>-6.832971</td>\n",
       "      <td>moderate</td>\n",
       "      <td>11.003709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3046</td>\n",
       "      <td>14.709268</td>\n",
       "      <td>14.705437</td>\n",
       "      <td>15.653622</td>\n",
       "      <td>13.795657</td>\n",
       "      <td>20.971365</td>\n",
       "      <td>10.914678</td>\n",
       "      <td>17.425029</td>\n",
       "      <td>15.206950</td>\n",
       "      <td>-11.543944</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.334498</td>\n",
       "      <td>-0.451702</td>\n",
       "      <td>1.413641</td>\n",
       "      <td>3.267479</td>\n",
       "      <td>1.614526</td>\n",
       "      <td>1.457636</td>\n",
       "      <td>-11.378422</td>\n",
       "      <td>-151.100608</td>\n",
       "      <td>moderate</td>\n",
       "      <td>17.397085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3283</td>\n",
       "      <td>5.833995</td>\n",
       "      <td>6.604345</td>\n",
       "      <td>2.363601</td>\n",
       "      <td>-9.255311</td>\n",
       "      <td>3.541783</td>\n",
       "      <td>4.677368</td>\n",
       "      <td>3.419846</td>\n",
       "      <td>1.931145</td>\n",
       "      <td>-30.113728</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.100160</td>\n",
       "      <td>3.108840</td>\n",
       "      <td>0.063384</td>\n",
       "      <td>3.092837</td>\n",
       "      <td>1.523644</td>\n",
       "      <td>1.486983</td>\n",
       "      <td>8.420694</td>\n",
       "      <td>24.461809</td>\n",
       "      <td>moderate</td>\n",
       "      <td>8.540650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4044</td>\n",
       "      <td>14.333394</td>\n",
       "      <td>13.808201</td>\n",
       "      <td>18.681990</td>\n",
       "      <td>51.246458</td>\n",
       "      <td>16.837010</td>\n",
       "      <td>12.740874</td>\n",
       "      <td>19.103214</td>\n",
       "      <td>18.158152</td>\n",
       "      <td>51.639965</td>\n",
       "      <td>...</td>\n",
       "      <td>8.315876</td>\n",
       "      <td>5.501720</td>\n",
       "      <td>0.966053</td>\n",
       "      <td>2.845833</td>\n",
       "      <td>0.952207</td>\n",
       "      <td>1.255815</td>\n",
       "      <td>-12.785290</td>\n",
       "      <td>-24.363242</td>\n",
       "      <td>moderate</td>\n",
       "      <td>8.575114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2343</td>\n",
       "      <td>15.439611</td>\n",
       "      <td>17.005719</td>\n",
       "      <td>16.209157</td>\n",
       "      <td>-1.440918</td>\n",
       "      <td>11.172942</td>\n",
       "      <td>8.459881</td>\n",
       "      <td>12.834418</td>\n",
       "      <td>4.049231</td>\n",
       "      <td>-35.656869</td>\n",
       "      <td>...</td>\n",
       "      <td>4.229461</td>\n",
       "      <td>-0.969258</td>\n",
       "      <td>-0.424363</td>\n",
       "      <td>3.010421</td>\n",
       "      <td>1.267441</td>\n",
       "      <td>0.792707</td>\n",
       "      <td>-26.840969</td>\n",
       "      <td>48.354919</td>\n",
       "      <td>low</td>\n",
       "      <td>18.487426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  robot_gear_compression_diff_1  weapon_robot_armour_index_2  \\\n",
       "0  3777                      13.493252                    13.203419   \n",
       "1  3046                      14.709268                    14.705437   \n",
       "2  3283                       5.833995                     6.604345   \n",
       "3  4044                      14.333394                    13.808201   \n",
       "4  2343                      15.439611                    17.005719   \n",
       "\n",
       "   robot_gear_compression_diff_3  robot_gear_compression_diff_4  \\\n",
       "0                      15.945541                      35.322252   \n",
       "1                      15.653622                      13.795657   \n",
       "2                       2.363601                      -9.255311   \n",
       "3                      18.681990                      51.246458   \n",
       "4                      16.209157                      -1.440918   \n",
       "\n",
       "   weapon_robot_punch_right_1  robot_gear_compression_diff_6  \\\n",
       "0                   18.592792                      11.956559   \n",
       "1                   20.971365                      10.914678   \n",
       "2                    3.541783                       4.677368   \n",
       "3                   16.837010                      12.740874   \n",
       "4                   11.172942                       8.459881   \n",
       "\n",
       "   robot_gear_compression_diff_7  robot_gear_compression_diff_8  \\\n",
       "0                      17.916364                      17.653934   \n",
       "1                      17.425029                      15.206950   \n",
       "2                       3.419846                       1.931145   \n",
       "3                      19.103214                      18.158152   \n",
       "4                      12.834418                       4.049231   \n",
       "\n",
       "   robot_gear_compression_diff_9    ...      robot_probe_temperature_5  \\\n",
       "0                      29.217912    ...                       2.887527   \n",
       "1                     -11.543944    ...                     -19.334498   \n",
       "2                     -30.113728    ...                      -5.100160   \n",
       "3                      51.639965    ...                       8.315876   \n",
       "4                     -35.656869    ...                       4.229461   \n",
       "\n",
       "   robot_probe_temperature_6  robot_probe_temperature_7  \\\n",
       "0                   3.375930                  -3.963133   \n",
       "1                  -0.451702                   1.413641   \n",
       "2                   3.108840                   0.063384   \n",
       "3                   5.501720                   0.966053   \n",
       "4                  -0.969258                  -0.424363   \n",
       "\n",
       "   robot_probe_temperature_8  robot_probe_temperature_9  \\\n",
       "0                   2.921440                   2.784923   \n",
       "1                   3.267479                   1.614526   \n",
       "2                   3.092837                   1.523644   \n",
       "3                   2.845833                   0.952207   \n",
       "4                   3.010421                   1.267441   \n",
       "\n",
       "   weapon_robot_eye_laser_range_1  weapon_robot_punch_left_4  \\\n",
       "0                        1.625606                  -0.647793   \n",
       "1                        1.457636                 -11.378422   \n",
       "2                        1.486983                   8.420694   \n",
       "3                        1.255815                 -12.785290   \n",
       "4                        0.792707                 -26.840969   \n",
       "\n",
       "   weapon_robot_punch_left_2  gamma_ray     target  \n",
       "0                  -6.832971   moderate  11.003709  \n",
       "1                -151.100608   moderate  17.397085  \n",
       "2                  24.461809   moderate   8.540650  \n",
       "3                 -24.363242   moderate   8.575114  \n",
       "4                  48.354919        low  18.487426  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = simple_encode(dataset)\n",
    "\n",
    "X = dataset.values[0::, 1:-1:]\n",
    "y = dataset.values[0::, -1]\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#X = scaler.fit_transform(X)\n",
    "#X = np.c_[(X, dataset.values[0::, -2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x120bf5f98>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_cols = [\"Regressor\", \"r2\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for reg in regressors:\n",
    "    name = reg.__class__.__name__\n",
    "    \n",
    "    acc = cross_validate(reg, X, y, scoring=['r2', 'neg_mean_squared_error'], cv=3, n_jobs=-1)\n",
    "    if name in acc_dict:\n",
    "        acc_dict[name] += acc\n",
    "    else:\n",
    "        acc_dict[name] = acc\n",
    "\n",
    "for reg in acc_dict:\n",
    "    log_entry = pd.DataFrame([[reg, acc_dict[reg]['test_r2'].mean()]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='r2', y='Regressor', data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train gradiend boosting regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще этот регрессор выглядит многообещающе, но я потратил на него уже три попытки и все были с отрицательным r2 -> я както неправильно подготавливаю данные. Скорее всего я где-то неправ со scaler'ом. А мб он прост не работает и не надо тратить на него время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[600:], X[:600]\n",
    "y_train, y_test = y[600:], y[:600]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_reg = GradientBoostingRegressor()\n",
    "gbr_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gbr_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923531001197886"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_set = pd.read_csv('./robot_data/test_data.csv')\n",
    "years = test_set['year']\n",
    "\n",
    "test_set = test_set.drop(columns=['year', 'target'])\n",
    "test_set = simple_encode(test_set)\n",
    "#print(test_set.head())\n",
    "y_pred = gbr_reg.predict(test_set)\n",
    "y_pred = y_pred.reshape(1000)\n",
    "\n",
    "\n",
    "d = {'year': years.values, 'target': y_pred}\n",
    "ans = pd.DataFrame(d)\n",
    "ans = ans.set_index('year')\n",
    "\n",
    "ans.to_csv('./submissions/subm_gbr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train mlp w\\ dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dropout_model(n_cols):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, activation='relu', input_shape=(n_cols,), kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               37120     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 2,007,297\n",
      "Trainable params: 2,007,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2130 samples, validate on 533 samples\n",
      "Epoch 1/100\n",
      "2130/2130 [==============================] - 2s 978us/step - loss: 696.0919 - coeff_determination: -0.2911 - val_loss: 273.0216 - val_coeff_determination: 0.6016\n",
      "Epoch 2/100\n",
      "2130/2130 [==============================] - 1s 607us/step - loss: 339.6724 - coeff_determination: 0.4830 - val_loss: 72.3666 - val_coeff_determination: 0.8385\n",
      "Epoch 3/100\n",
      "2130/2130 [==============================] - 2s 733us/step - loss: 159.1130 - coeff_determination: 0.7506 - val_loss: 113.2778 - val_coeff_determination: 0.7051\n",
      "Epoch 4/100\n",
      "2130/2130 [==============================] - 2s 747us/step - loss: 93.7863 - coeff_determination: 0.8068 - val_loss: 664.6999 - val_coeff_determination: 0.2557\n",
      "Epoch 5/100\n",
      "2130/2130 [==============================] - 2s 746us/step - loss: 97.4107 - coeff_determination: 0.8161 - val_loss: 71.3025 - val_coeff_determination: 0.8836\n",
      "Epoch 6/100\n",
      "2130/2130 [==============================] - 2s 729us/step - loss: 140.8556 - coeff_determination: 0.8078 - val_loss: 71.8420 - val_coeff_determination: 0.7973\n",
      "Epoch 7/100\n",
      "2130/2130 [==============================] - 1s 663us/step - loss: 161.2378 - coeff_determination: 0.7612 - val_loss: 89.2999 - val_coeff_determination: 0.7924\n",
      "Epoch 8/100\n",
      "2130/2130 [==============================] - 1s 605us/step - loss: 184.5686 - coeff_determination: 0.7531 - val_loss: 143.9958 - val_coeff_determination: 0.8357\n",
      "Epoch 9/100\n",
      "2130/2130 [==============================] - 1s 662us/step - loss: 238.7446 - coeff_determination: 0.7282 - val_loss: 123.1872 - val_coeff_determination: 0.7862\n",
      "Epoch 10/100\n",
      "2130/2130 [==============================] - 2s 712us/step - loss: 124.2516 - coeff_determination: 0.7944 - val_loss: 73.0257 - val_coeff_determination: 0.8350\n",
      "Epoch 11/100\n",
      "2130/2130 [==============================] - 1s 697us/step - loss: 82.5516 - coeff_determination: 0.8651 - val_loss: 48.8445 - val_coeff_determination: 0.9026\n",
      "Epoch 12/100\n",
      "2130/2130 [==============================] - 2s 717us/step - loss: 157.4351 - coeff_determination: 0.8174 - val_loss: 130.2036 - val_coeff_determination: 0.8130\n",
      "Epoch 13/100\n",
      "2130/2130 [==============================] - 2s 718us/step - loss: 45.9090 - coeff_determination: 0.8787 - val_loss: 109.0892 - val_coeff_determination: 0.7777\n",
      "Epoch 14/100\n",
      "2130/2130 [==============================] - 2s 743us/step - loss: 81.3165 - coeff_determination: 0.8783 - val_loss: 78.6297 - val_coeff_determination: 0.8354\n",
      "Epoch 15/100\n",
      "2130/2130 [==============================] - 2s 737us/step - loss: 169.4074 - coeff_determination: 0.8037 - val_loss: 181.7763 - val_coeff_determination: 0.7203\n",
      "Epoch 16/100\n",
      "2130/2130 [==============================] - 2s 704us/step - loss: 167.2490 - coeff_determination: 0.7860 - val_loss: 104.2107 - val_coeff_determination: 0.8040\n",
      "Epoch 17/100\n",
      "2130/2130 [==============================] - 1s 695us/step - loss: 139.9712 - coeff_determination: 0.8182 - val_loss: 28.6824 - val_coeff_determination: 0.8789\n",
      "Epoch 18/100\n",
      "2130/2130 [==============================] - 2s 718us/step - loss: 54.0735 - coeff_determination: 0.9073 - val_loss: 317.7066 - val_coeff_determination: 0.6855\n",
      "Epoch 19/100\n",
      "2130/2130 [==============================] - 2s 711us/step - loss: 66.9734 - coeff_determination: 0.8619 - val_loss: 51.4103 - val_coeff_determination: 0.8176\n",
      "Epoch 20/100\n",
      "2130/2130 [==============================] - 2s 708us/step - loss: 102.1117 - coeff_determination: 0.8647 - val_loss: 123.3865 - val_coeff_determination: 0.7517\n",
      "Epoch 21/100\n",
      "2130/2130 [==============================] - 2s 739us/step - loss: 45.6458 - coeff_determination: 0.8896 - val_loss: 120.3059 - val_coeff_determination: 0.8300\n",
      "Epoch 22/100\n",
      "2130/2130 [==============================] - 2s 732us/step - loss: 132.3102 - coeff_determination: 0.8167 - val_loss: 61.0768 - val_coeff_determination: 0.8637\n",
      "Epoch 23/100\n",
      "2130/2130 [==============================] - 1s 703us/step - loss: 101.6794 - coeff_determination: 0.8721 - val_loss: 115.0630 - val_coeff_determination: 0.8426\n",
      "Epoch 24/100\n",
      "2130/2130 [==============================] - 1s 703us/step - loss: 68.0916 - coeff_determination: 0.8974 - val_loss: 83.7246 - val_coeff_determination: 0.8179\n",
      "Epoch 25/100\n",
      "2130/2130 [==============================] - 1s 653us/step - loss: 91.2531 - coeff_determination: 0.8976 - val_loss: 79.8195 - val_coeff_determination: 0.8448\n",
      "Epoch 26/100\n",
      "2130/2130 [==============================] - 1s 672us/step - loss: 30.0811 - coeff_determination: 0.9248 - val_loss: 26.4452 - val_coeff_determination: 0.8869\n",
      "Epoch 27/100\n",
      "2130/2130 [==============================] - 1s 688us/step - loss: 47.6557 - coeff_determination: 0.9154 - val_loss: 26.6857 - val_coeff_determination: 0.8931\n",
      "Epoch 28/100\n",
      "2130/2130 [==============================] - 1s 682us/step - loss: 54.1404 - coeff_determination: 0.9168 - val_loss: 90.9213 - val_coeff_determination: 0.8432\n",
      "Epoch 29/100\n",
      "2130/2130 [==============================] - 1s 659us/step - loss: 59.2481 - coeff_determination: 0.8936 - val_loss: 26.5307 - val_coeff_determination: 0.8799\n",
      "Epoch 30/100\n",
      "2130/2130 [==============================] - 1s 605us/step - loss: 30.5836 - coeff_determination: 0.9349 - val_loss: 26.0288 - val_coeff_determination: 0.8912\n",
      "Epoch 31/100\n",
      "2130/2130 [==============================] - 1s 573us/step - loss: 32.4245 - coeff_determination: 0.9250 - val_loss: 103.3731 - val_coeff_determination: 0.8295\n",
      "Epoch 32/100\n",
      "2130/2130 [==============================] - 1s 685us/step - loss: 68.4317 - coeff_determination: 0.8991 - val_loss: 26.1865 - val_coeff_determination: 0.8948\n",
      "Epoch 33/100\n",
      "2130/2130 [==============================] - 1s 682us/step - loss: 58.9503 - coeff_determination: 0.9079 - val_loss: 72.7567 - val_coeff_determination: 0.8496\n",
      "Epoch 34/100\n",
      "2130/2130 [==============================] - 1s 630us/step - loss: 99.6736 - coeff_determination: 0.8349 - val_loss: 63.7145 - val_coeff_determination: 0.8596\n",
      "Epoch 35/100\n",
      "2130/2130 [==============================] - 1s 703us/step - loss: 110.9075 - coeff_determination: 0.8278 - val_loss: 28.0873 - val_coeff_determination: 0.8781\n",
      "Epoch 36/100\n",
      "2130/2130 [==============================] - 2s 721us/step - loss: 49.5025 - coeff_determination: 0.9095 - val_loss: 194.0279 - val_coeff_determination: 0.6595\n",
      "Epoch 37/100\n",
      "2130/2130 [==============================] - 2s 732us/step - loss: 95.1606 - coeff_determination: 0.8744 - val_loss: 162.0615 - val_coeff_determination: 0.7445\n",
      "Epoch 38/100\n",
      "2130/2130 [==============================] - 2s 708us/step - loss: 43.9992 - coeff_determination: 0.9152 - val_loss: 29.9208 - val_coeff_determination: 0.8992\n",
      "Epoch 39/100\n",
      "2130/2130 [==============================] - 1s 693us/step - loss: 50.9875 - coeff_determination: 0.9157 - val_loss: 35.6414 - val_coeff_determination: 0.8736\n",
      "Epoch 40/100\n",
      "2130/2130 [==============================] - 1s 659us/step - loss: 34.4945 - coeff_determination: 0.9275 - val_loss: 25.1863 - val_coeff_determination: 0.8976\n",
      "Epoch 41/100\n",
      "2130/2130 [==============================] - 1s 636us/step - loss: 37.5621 - coeff_determination: 0.9368 - val_loss: 23.4417 - val_coeff_determination: 0.8908\n",
      "Epoch 42/100\n",
      "2130/2130 [==============================] - 1s 653us/step - loss: 42.4230 - coeff_determination: 0.9328 - val_loss: 39.7937 - val_coeff_determination: 0.8573\n",
      "Epoch 43/100\n",
      "2130/2130 [==============================] - 1s 691us/step - loss: 47.1239 - coeff_determination: 0.9234 - val_loss: 63.6818 - val_coeff_determination: 0.8716\n",
      "Epoch 44/100\n",
      "2130/2130 [==============================] - 1s 679us/step - loss: 42.8208 - coeff_determination: 0.9298 - val_loss: 29.1419 - val_coeff_determination: 0.8786\n",
      "Epoch 45/100\n",
      "2130/2130 [==============================] - 1s 645us/step - loss: 32.7253 - coeff_determination: 0.9311 - val_loss: 70.6568 - val_coeff_determination: 0.8643\n",
      "Epoch 46/100\n",
      "2130/2130 [==============================] - 1s 682us/step - loss: 49.7463 - coeff_determination: 0.9196 - val_loss: 102.6119 - val_coeff_determination: 0.8147\n",
      "Epoch 47/100\n",
      "2130/2130 [==============================] - 1s 696us/step - loss: 43.6370 - coeff_determination: 0.9297 - val_loss: 46.0538 - val_coeff_determination: 0.8601\n",
      "Epoch 48/100\n",
      "2130/2130 [==============================] - 1s 674us/step - loss: 46.8963 - coeff_determination: 0.9276 - val_loss: 29.2346 - val_coeff_determination: 0.8804\n",
      "Epoch 49/100\n",
      "2130/2130 [==============================] - 1s 686us/step - loss: 58.8775 - coeff_determination: 0.9049 - val_loss: 209.6268 - val_coeff_determination: 0.6607\n",
      "Epoch 50/100\n",
      "2130/2130 [==============================] - 1s 645us/step - loss: 114.9239 - coeff_determination: 0.8702 - val_loss: 68.2287 - val_coeff_determination: 0.8383\n",
      "Epoch 51/100\n",
      "2130/2130 [==============================] - 1s 606us/step - loss: 65.6528 - coeff_determination: 0.8792 - val_loss: 27.2273 - val_coeff_determination: 0.9087\n",
      "Epoch 52/100\n",
      "2130/2130 [==============================] - 1s 629us/step - loss: 68.1459 - coeff_determination: 0.9093 - val_loss: 23.0546 - val_coeff_determination: 0.8972\n",
      "Epoch 53/100\n",
      "2130/2130 [==============================] - 1s 654us/step - loss: 81.8207 - coeff_determination: 0.8838 - val_loss: 33.8284 - val_coeff_determination: 0.8857\n",
      "Epoch 54/100\n",
      "2130/2130 [==============================] - 1s 651us/step - loss: 143.2836 - coeff_determination: 0.8352 - val_loss: 34.5879 - val_coeff_determination: 0.8568\n",
      "Epoch 55/100\n",
      "2130/2130 [==============================] - 1s 664us/step - loss: 99.8387 - coeff_determination: 0.8623 - val_loss: 39.8168 - val_coeff_determination: 0.8261\n",
      "Epoch 56/100\n",
      "2130/2130 [==============================] - 1s 690us/step - loss: 95.0677 - coeff_determination: 0.8726 - val_loss: 37.6889 - val_coeff_determination: 0.8500\n",
      "Epoch 57/100\n",
      "2130/2130 [==============================] - 2s 720us/step - loss: 66.4108 - coeff_determination: 0.9098 - val_loss: 74.3046 - val_coeff_determination: 0.7971\n",
      "Epoch 58/100\n",
      "2130/2130 [==============================] - 2s 709us/step - loss: 29.1245 - coeff_determination: 0.9349 - val_loss: 39.3579 - val_coeff_determination: 0.8124\n",
      "Epoch 59/100\n",
      "2130/2130 [==============================] - 1s 695us/step - loss: 74.1057 - coeff_determination: 0.8790 - val_loss: 107.8278 - val_coeff_determination: 0.7918\n",
      "Epoch 60/100\n",
      "2130/2130 [==============================] - 1s 697us/step - loss: 60.8642 - coeff_determination: 0.9075 - val_loss: 40.0575 - val_coeff_determination: 0.8733\n",
      "Epoch 61/100\n",
      "2130/2130 [==============================] - 2s 720us/step - loss: 77.2224 - coeff_determination: 0.8978 - val_loss: 57.5470 - val_coeff_determination: 0.8137\n",
      "Epoch 62/100\n",
      "2130/2130 [==============================] - 2s 724us/step - loss: 83.9557 - coeff_determination: 0.8620 - val_loss: 30.3918 - val_coeff_determination: 0.8668\n",
      "Epoch 63/100\n",
      "2130/2130 [==============================] - 2s 713us/step - loss: 121.7026 - coeff_determination: 0.8595 - val_loss: 28.3740 - val_coeff_determination: 0.8944\n",
      "Epoch 64/100\n",
      "2130/2130 [==============================] - 2s 727us/step - loss: 61.2254 - coeff_determination: 0.8930 - val_loss: 131.4062 - val_coeff_determination: 0.7342\n",
      "Epoch 65/100\n",
      "2130/2130 [==============================] - 1s 690us/step - loss: 89.9623 - coeff_determination: 0.8710 - val_loss: 76.0396 - val_coeff_determination: 0.8131\n",
      "Epoch 66/100\n",
      "2130/2130 [==============================] - 1s 696us/step - loss: 59.8525 - coeff_determination: 0.9107 - val_loss: 36.2957 - val_coeff_determination: 0.8771\n",
      "Epoch 67/100\n",
      "2130/2130 [==============================] - 2s 735us/step - loss: 153.0251 - coeff_determination: 0.8538 - val_loss: 118.7098 - val_coeff_determination: 0.8192\n",
      "Epoch 68/100\n",
      "2130/2130 [==============================] - 2s 714us/step - loss: 58.9082 - coeff_determination: 0.9181 - val_loss: 45.7712 - val_coeff_determination: 0.8732\n",
      "Epoch 69/100\n",
      "2130/2130 [==============================] - 2s 717us/step - loss: 86.7595 - coeff_determination: 0.8878 - val_loss: 25.3416 - val_coeff_determination: 0.8906\n",
      "Epoch 70/100\n",
      "2130/2130 [==============================] - 2s 727us/step - loss: 59.3804 - coeff_determination: 0.9113 - val_loss: 44.4825 - val_coeff_determination: 0.8595\n",
      "Epoch 71/100\n",
      "2130/2130 [==============================] - 2s 714us/step - loss: 55.3663 - coeff_determination: 0.9145 - val_loss: 114.1923 - val_coeff_determination: 0.7906\n",
      "Epoch 72/100\n",
      "2130/2130 [==============================] - 2s 745us/step - loss: 129.0863 - coeff_determination: 0.8493 - val_loss: 131.3132 - val_coeff_determination: 0.7639\n",
      "Epoch 73/100\n",
      "2130/2130 [==============================] - 1s 696us/step - loss: 152.4986 - coeff_determination: 0.8044 - val_loss: 40.9540 - val_coeff_determination: 0.8708\n",
      "Epoch 74/100\n",
      "2130/2130 [==============================] - 1s 644us/step - loss: 162.4398 - coeff_determination: 0.8413 - val_loss: 81.3657 - val_coeff_determination: 0.8369\n",
      "Epoch 75/100\n",
      "2130/2130 [==============================] - 1s 697us/step - loss: 77.4568 - coeff_determination: 0.8932 - val_loss: 84.7871 - val_coeff_determination: 0.8238\n",
      "Epoch 76/100\n",
      "2130/2130 [==============================] - 1s 698us/step - loss: 196.0493 - coeff_determination: 0.8146 - val_loss: 221.0691 - val_coeff_determination: 0.6120\n",
      "Epoch 77/100\n",
      "2130/2130 [==============================] - 2s 749us/step - loss: 299.2614 - coeff_determination: 0.7584 - val_loss: 198.0524 - val_coeff_determination: 0.6729\n",
      "Epoch 78/100\n",
      "2130/2130 [==============================] - 1s 693us/step - loss: 41.6525 - coeff_determination: 0.9179 - val_loss: 95.5173 - val_coeff_determination: 0.7967\n",
      "Epoch 79/100\n",
      "2130/2130 [==============================] - 1s 680us/step - loss: 45.5685 - coeff_determination: 0.9227 - val_loss: 39.8107 - val_coeff_determination: 0.8549\n",
      "Epoch 80/100\n",
      "2130/2130 [==============================] - 1s 703us/step - loss: 76.1306 - coeff_determination: 0.9029 - val_loss: 66.3234 - val_coeff_determination: 0.7488\n",
      "Epoch 81/100\n",
      "2130/2130 [==============================] - 1s 681us/step - loss: 50.5587 - coeff_determination: 0.9211 - val_loss: 103.5500 - val_coeff_determination: 0.7845\n",
      "Epoch 82/100\n",
      "2130/2130 [==============================] - 2s 720us/step - loss: 60.3501 - coeff_determination: 0.9230 - val_loss: 32.1486 - val_coeff_determination: 0.9094\n",
      "Epoch 83/100\n",
      "2130/2130 [==============================] - 2s 718us/step - loss: 39.2370 - coeff_determination: 0.9397 - val_loss: 37.7354 - val_coeff_determination: 0.8522\n",
      "Epoch 84/100\n",
      "2130/2130 [==============================] - 2s 737us/step - loss: 34.9339 - coeff_determination: 0.9407 - val_loss: 36.8419 - val_coeff_determination: 0.8470\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 2s 723us/step - loss: 39.9621 - coeff_determination: 0.9131 - val_loss: 46.1296 - val_coeff_determination: 0.8437\n",
      "Epoch 86/100\n",
      "2130/2130 [==============================] - 2s 722us/step - loss: 26.7108 - coeff_determination: 0.9474 - val_loss: 35.6812 - val_coeff_determination: 0.8466\n",
      "Epoch 87/100\n",
      "2130/2130 [==============================] - 1s 698us/step - loss: 62.4814 - coeff_determination: 0.9224 - val_loss: 117.0677 - val_coeff_determination: 0.7699\n",
      "Epoch 88/100\n",
      "2130/2130 [==============================] - 2s 715us/step - loss: 49.3457 - coeff_determination: 0.9109 - val_loss: 33.7994 - val_coeff_determination: 0.8422\n",
      "Epoch 89/100\n",
      "2130/2130 [==============================] - 2s 715us/step - loss: 48.3071 - coeff_determination: 0.9195 - val_loss: 70.9535 - val_coeff_determination: 0.8584\n",
      "Epoch 90/100\n",
      "2130/2130 [==============================] - 2s 708us/step - loss: 108.1693 - coeff_determination: 0.8776 - val_loss: 84.9357 - val_coeff_determination: 0.8349\n",
      "Epoch 91/100\n",
      "2130/2130 [==============================] - 2s 718us/step - loss: 95.8935 - coeff_determination: 0.8794 - val_loss: 153.3059 - val_coeff_determination: 0.7004\n",
      "Epoch 92/100\n",
      "2130/2130 [==============================] - 1s 687us/step - loss: 64.1153 - coeff_determination: 0.8962 - val_loss: 35.1723 - val_coeff_determination: 0.8384\n",
      "Epoch 93/100\n",
      "2130/2130 [==============================] - 2s 709us/step - loss: 71.1390 - coeff_determination: 0.9084 - val_loss: 108.4240 - val_coeff_determination: 0.7890\n",
      "Epoch 94/100\n",
      "2130/2130 [==============================] - 1s 680us/step - loss: 46.7418 - coeff_determination: 0.9312 - val_loss: 40.8110 - val_coeff_determination: 0.8464\n",
      "Epoch 95/100\n",
      "2130/2130 [==============================] - 2s 729us/step - loss: 42.9561 - coeff_determination: 0.9333 - val_loss: 109.5613 - val_coeff_determination: 0.7793\n",
      "Epoch 96/100\n",
      "2130/2130 [==============================] - 2s 710us/step - loss: 54.7561 - coeff_determination: 0.9203 - val_loss: 84.6964 - val_coeff_determination: 0.8162\n",
      "Epoch 97/100\n",
      "2130/2130 [==============================] - 2s 711us/step - loss: 82.0718 - coeff_determination: 0.9066 - val_loss: 128.0114 - val_coeff_determination: 0.8029\n",
      "Epoch 98/100\n",
      "2130/2130 [==============================] - 2s 713us/step - loss: 90.5932 - coeff_determination: 0.8927 - val_loss: 157.4203 - val_coeff_determination: 0.7499\n",
      "Epoch 99/100\n",
      "2130/2130 [==============================] - 1s 666us/step - loss: 149.4428 - coeff_determination: 0.8409 - val_loss: 165.5429 - val_coeff_determination: 0.7433\n",
      "Epoch 100/100\n",
      "2130/2130 [==============================] - 1s 678us/step - loss: 58.7979 - coeff_determination: 0.9193 - val_loss: 44.3325 - val_coeff_determination: 0.8905\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(df, 600, 'simple')\n",
    "\n",
    "verbose = 1 # выводить ли инфу в процессе обучения (на гитхаб лучше не заливать когда verbose > 0, а просто перетренировать с = 0)\n",
    "            # 0 - silence \n",
    "            # 1 - progress bar\n",
    "            # 2 - line per epoch \n",
    "model = create_dropout_model(X_train.shape[1])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[coeff_determination])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 110us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[31.21619177500407, 0.8982356762886048]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submition(model, subm_name='./submissions/subm_mlp_dropout_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
