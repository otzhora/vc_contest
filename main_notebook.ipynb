{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import json \n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import parallel_backend\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('robot_data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>robot_gear_compression_diff_1</th>\n",
       "      <th>weapon_robot_armour_index_2</th>\n",
       "      <th>robot_gear_compression_diff_3</th>\n",
       "      <th>robot_gear_compression_diff_4</th>\n",
       "      <th>weapon_robot_punch_right_1</th>\n",
       "      <th>robot_gear_compression_diff_6</th>\n",
       "      <th>robot_gear_compression_diff_7</th>\n",
       "      <th>robot_gear_compression_diff_8</th>\n",
       "      <th>robot_gear_compression_diff_9</th>\n",
       "      <th>robot_gear_compression_diff_10</th>\n",
       "      <th>...</th>\n",
       "      <th>robot_probe_temperature_5</th>\n",
       "      <th>robot_probe_temperature_6</th>\n",
       "      <th>robot_probe_temperature_7</th>\n",
       "      <th>robot_probe_temperature_8</th>\n",
       "      <th>robot_probe_temperature_9</th>\n",
       "      <th>weapon_robot_eye_laser_range_1</th>\n",
       "      <th>weapon_robot_punch_left_4</th>\n",
       "      <th>weapon_robot_punch_left_2</th>\n",
       "      <th>gamma_ray</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.283534</td>\n",
       "      <td>-0.837881</td>\n",
       "      <td>-3.597984</td>\n",
       "      <td>-16.554849</td>\n",
       "      <td>-11.389089</td>\n",
       "      <td>0.313589</td>\n",
       "      <td>-3.383178</td>\n",
       "      <td>-3.888150</td>\n",
       "      <td>-41.686393</td>\n",
       "      <td>-8.679487</td>\n",
       "      <td>...</td>\n",
       "      <td>5.967009</td>\n",
       "      <td>3.982668</td>\n",
       "      <td>1.174039</td>\n",
       "      <td>2.875162</td>\n",
       "      <td>1.261036</td>\n",
       "      <td>1.075103</td>\n",
       "      <td>-0.647793</td>\n",
       "      <td>-7.049394</td>\n",
       "      <td>moderate</td>\n",
       "      <td>-2.316919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.142603</td>\n",
       "      <td>-6.924267</td>\n",
       "      <td>-5.764813</td>\n",
       "      <td>8.312981</td>\n",
       "      <td>-18.293047</td>\n",
       "      <td>-6.217982</td>\n",
       "      <td>-12.931946</td>\n",
       "      <td>-7.927816</td>\n",
       "      <td>27.126724</td>\n",
       "      <td>-11.829680</td>\n",
       "      <td>...</td>\n",
       "      <td>9.444724</td>\n",
       "      <td>4.856028</td>\n",
       "      <td>-2.257161</td>\n",
       "      <td>3.229065</td>\n",
       "      <td>1.408525</td>\n",
       "      <td>1.305627</td>\n",
       "      <td>8.870408</td>\n",
       "      <td>-0.643271</td>\n",
       "      <td>high</td>\n",
       "      <td>-4.803426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.848547</td>\n",
       "      <td>-4.995010</td>\n",
       "      <td>-7.226481</td>\n",
       "      <td>-10.701620</td>\n",
       "      <td>-19.433779</td>\n",
       "      <td>-2.741447</td>\n",
       "      <td>-7.059371</td>\n",
       "      <td>-7.322945</td>\n",
       "      <td>-25.596221</td>\n",
       "      <td>-12.577888</td>\n",
       "      <td>...</td>\n",
       "      <td>4.949442</td>\n",
       "      <td>3.990456</td>\n",
       "      <td>0.198023</td>\n",
       "      <td>3.106897</td>\n",
       "      <td>2.477999</td>\n",
       "      <td>1.437429</td>\n",
       "      <td>10.733607</td>\n",
       "      <td>-6.703117</td>\n",
       "      <td>high</td>\n",
       "      <td>-8.582892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.869959</td>\n",
       "      <td>7.545168</td>\n",
       "      <td>2.551952</td>\n",
       "      <td>-17.619413</td>\n",
       "      <td>-2.619880</td>\n",
       "      <td>2.451828</td>\n",
       "      <td>1.046444</td>\n",
       "      <td>-7.585662</td>\n",
       "      <td>-46.879829</td>\n",
       "      <td>6.168043</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.464548</td>\n",
       "      <td>-13.233923</td>\n",
       "      <td>2.084878</td>\n",
       "      <td>3.155285</td>\n",
       "      <td>1.556361</td>\n",
       "      <td>1.596260</td>\n",
       "      <td>-11.369326</td>\n",
       "      <td>-198.627120</td>\n",
       "      <td>moderate</td>\n",
       "      <td>-13.795526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.104006</td>\n",
       "      <td>15.290944</td>\n",
       "      <td>14.629884</td>\n",
       "      <td>1.226133</td>\n",
       "      <td>29.296182</td>\n",
       "      <td>10.653833</td>\n",
       "      <td>15.296214</td>\n",
       "      <td>8.833471</td>\n",
       "      <td>-32.645455</td>\n",
       "      <td>30.281082</td>\n",
       "      <td>...</td>\n",
       "      <td>3.692965</td>\n",
       "      <td>2.991953</td>\n",
       "      <td>2.221670</td>\n",
       "      <td>3.401771</td>\n",
       "      <td>2.434549</td>\n",
       "      <td>2.023328</td>\n",
       "      <td>-11.648547</td>\n",
       "      <td>77.482138</td>\n",
       "      <td>low</td>\n",
       "      <td>16.475245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   robot_gear_compression_diff_1  weapon_robot_armour_index_2  \\\n",
       "0                      -0.283534                    -0.837881   \n",
       "1                      -5.142603                    -6.924267   \n",
       "2                      -4.848547                    -4.995010   \n",
       "3                       9.869959                     7.545168   \n",
       "4                      14.104006                    15.290944   \n",
       "\n",
       "   robot_gear_compression_diff_3  robot_gear_compression_diff_4  \\\n",
       "0                      -3.597984                     -16.554849   \n",
       "1                      -5.764813                       8.312981   \n",
       "2                      -7.226481                     -10.701620   \n",
       "3                       2.551952                     -17.619413   \n",
       "4                      14.629884                       1.226133   \n",
       "\n",
       "   weapon_robot_punch_right_1  robot_gear_compression_diff_6  \\\n",
       "0                  -11.389089                       0.313589   \n",
       "1                  -18.293047                      -6.217982   \n",
       "2                  -19.433779                      -2.741447   \n",
       "3                   -2.619880                       2.451828   \n",
       "4                   29.296182                      10.653833   \n",
       "\n",
       "   robot_gear_compression_diff_7  robot_gear_compression_diff_8  \\\n",
       "0                      -3.383178                      -3.888150   \n",
       "1                     -12.931946                      -7.927816   \n",
       "2                      -7.059371                      -7.322945   \n",
       "3                       1.046444                      -7.585662   \n",
       "4                      15.296214                       8.833471   \n",
       "\n",
       "   robot_gear_compression_diff_9  robot_gear_compression_diff_10    ...      \\\n",
       "0                     -41.686393                       -8.679487    ...       \n",
       "1                      27.126724                      -11.829680    ...       \n",
       "2                     -25.596221                      -12.577888    ...       \n",
       "3                     -46.879829                        6.168043    ...       \n",
       "4                     -32.645455                       30.281082    ...       \n",
       "\n",
       "   robot_probe_temperature_5  robot_probe_temperature_6  \\\n",
       "0                   5.967009                   3.982668   \n",
       "1                   9.444724                   4.856028   \n",
       "2                   4.949442                   3.990456   \n",
       "3                 -32.464548                 -13.233923   \n",
       "4                   3.692965                   2.991953   \n",
       "\n",
       "   robot_probe_temperature_7  robot_probe_temperature_8  \\\n",
       "0                   1.174039                   2.875162   \n",
       "1                  -2.257161                   3.229065   \n",
       "2                   0.198023                   3.106897   \n",
       "3                   2.084878                   3.155285   \n",
       "4                   2.221670                   3.401771   \n",
       "\n",
       "   robot_probe_temperature_9  weapon_robot_eye_laser_range_1  \\\n",
       "0                   1.261036                        1.075103   \n",
       "1                   1.408525                        1.305627   \n",
       "2                   2.477999                        1.437429   \n",
       "3                   1.556361                        1.596260   \n",
       "4                   2.434549                        2.023328   \n",
       "\n",
       "   weapon_robot_punch_left_4  weapon_robot_punch_left_2  gamma_ray     target  \n",
       "0                  -0.647793                  -7.049394   moderate  -2.316919  \n",
       "1                   8.870408                  -0.643271       high  -4.803426  \n",
       "2                  10.733607                  -6.703117       high  -8.582892  \n",
       "3                 -11.369326                -198.627120   moderate -13.795526  \n",
       "4                 -11.648547                  77.482138        low  16.475245  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом датасете есть только 1 категориальная фича, которую мы можем кодировать или через onehot или прост сопоставить каждому значению чилсо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode cat features with oneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "\n",
    "# df_oh = oneHotEncode(df, ['gamma_ray'])\n",
    "# df_oh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode cat fetures with simple encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_encode(df, encode_map=None):\n",
    "    if not encode_map:\n",
    "        encode_map = {'low': 0.25, 'moderate': 0.5, 'high': 0.75, 'very high': 1}\n",
    "\n",
    "    df['gamma_ray'] = df['gamma_ray'].map(encode_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "# df_sim = simple_encode(df)\n",
    "# df_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем засплитить наш размеченный датасет на сет для тренировки и сет для теста модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сплит не в процентах, а в количестве семплов потому что бибу соси\n",
    "\n",
    "def split_train_test(df, split=600, enc_type='simple'):\n",
    "    if enc_type == 'simple':\n",
    "        df_ = simple_encode(df.copy())\n",
    "        X_train, y_train= df_.iloc[split:].drop(columns=['target'], inplace=False), df_.iloc[split:]['target']\n",
    "        X_test, y_test = df_.iloc[:split].drop(columns=['target'], inplace=False), df_.iloc[:split]['target']\n",
    "    elif enc_type == 'onehot':\n",
    "        df_ = oneHotEncode(df.copy(), ['gamma_ray'])\n",
    "        X_train, y_train = df_.iloc[split:].drop(columns=['target'], inplace=False), df_.iloc[split:]['target']\n",
    "        X_test, y_test = df_.iloc[:split].drop(columns=['target'], inplace=False), df_.iloc[:split]['target']\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# X_train, y_train, X_test, y_test = split_train_test(df, 600, 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настятельно рекомендую юзать поле enc (на каком энкодере обучалась)\n",
    "# acc ввеодить без точки, eg: r2 = 0.979 => acc = 979\n",
    "def save_model(model, acc, enc=''):\n",
    "    json_arch = model.to_json()\n",
    "    if enc:\n",
    "        model.save('./models/model_{}_{}.h5'.format(acc, enc))\n",
    "        with open('./arch/model_{}_{}.json'.format(acc, enc), 'w') as out:\n",
    "            out.write(json_arch)\n",
    "    else:\n",
    "        model.save('./models/model_{}.h5'.format(acc))\n",
    "        with open('./arch/model_{}.json'.format(acc), 'w') as out:\n",
    "            out.write(json_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train mlp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создавать все модели меняя эту функцию не самая лучшая идея, поэтому когда делаете новую модель лучше всего написать новую функцию аналагичную этой (да и вообще лучше целую секцию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_cols):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, activation='relu', input_shape=(n_cols,), kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2 metric \n",
    "\n",
    "${R^2 = \\frac{\\sum{(y_i - \\hat{y_i})^2}}{\\sum{(y_i - \\bar{y})^2}}}$\n",
    "\n",
    "${\\hat{y_i}}$ -- предсказанное значение \n",
    "${\\bar{y}}$ -- среднее значение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(df, 600, 'simple')\n",
    "\n",
    "verbose = 0 # выводить ли инфу в процессе обучения (на гитхаб лучше не заливать когда verbose > 0, а просто перетренировать с = 0, ну или если это долго то перед комитом очистить оутпуты)\n",
    "            # 0 - silence \n",
    "            # 1 - progress bar\n",
    "            # 2 - line per epoch \n",
    "model = create_model(X_train.shape[1])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[coeff_determination])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=400, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся инфа про обучение лежит в history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.954663671650985,\n",
       " 0.9532649177100376,\n",
       " 0.9533832158201407,\n",
       " 0.9565746234013484,\n",
       " 0.9501687149616835,\n",
       " 0.9580100864227896,\n",
       " 0.9519670936672147,\n",
       " 0.9602311026535607,\n",
       " 0.9531387005693246,\n",
       " 0.9597226503195055]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_coeff_determination'][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "полный аналог r2 метрики определенной выше, но написсаный на numpy (r2 метрика выше возвращяет tensor, что нужно для использования в керасе, но это не удобно чтобы тестить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_r2_score(v_true, v_pred):\n",
    "    ssres = np.sum(np.square(v_true - v_pred))\n",
    "    sstot = np.sum(np.square(v_true - np.mean(v_true)))\n",
    "    return 1 - ssres / sstot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие три ячейки тут потому что я так хочу "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620511907304891"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.shape = (y_pred.shape[0], )\n",
    "np_r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23052085471795541"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test - y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.936997877756754, 0.9407667374610901]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 940, 'simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_full_set(enc='simple', create_model=create_model, epochs=400, verbose=0):\n",
    "    dataset = pd.read_csv('./robot_data/train_data.csv')    \n",
    "    dataset = dataset.drop(columns=['year'])\n",
    "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    X_train, y_train, X_test, y_test = split_train_test(dataset, 0, enc)\n",
    "    model = create_model(X_train.shape[1])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[coeff_determination])\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, verbose=verbose)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_full_set()\n",
    "\n",
    "#model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try learn not only nn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    DecisionTreeRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    GradientBoostingRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./robot_data/train_data.csv') \n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "скейлим датасет и сопоставляем значения категориям "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = simple_encode(dataset)\n",
    "\n",
    "X = dataset.values[0::, :-2:]\n",
    "y = dataset.values[0::, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X = np.c_[(X, dataset.values[0::, -2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3d3e1c18>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_cols = [\"Regressor\", \"r2\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for reg in regressors:\n",
    "    name = reg.__class__.__name__\n",
    "    \n",
    "    acc = cross_validate(reg, X, y, scoring=['r2', 'neg_mean_squared_error'], cv=3, n_jobs=-1)\n",
    "    if name in acc_dict:\n",
    "        acc_dict[name] += acc\n",
    "    else:\n",
    "        acc_dict[name] = acc\n",
    "\n",
    "for reg in acc_dict:\n",
    "    log_entry = pd.DataFrame([[reg, acc_dict[reg]['test_r2'].mean()]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='r2', y='Regressor', data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train gradiend boosting regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще этот регрессор выглядит многообещающе, но я потратил на него уже три попытки и все были с отрицательным r2 -> я както неправильно подготавливаю данные. Скорее всего я где-то неправ со scaler'ом. А мб он прост не работает и не надо тратить на него время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = X[600:], X[:600]\n",
    "y_train, y_test = y[600:], y[:600]\n",
    "\n",
    "gbr_reg = GradientBoostingRegressor()\n",
    "gbr_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gbr_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9926041262413985"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train mlp w\\ dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dropout_model(n_cols):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, activation='relu', input_shape=(n_cols,), kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 128)               18560     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 249,217\n",
      "Trainable params: 249,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2130 samples, validate on 533 samples\n",
      "Epoch 1/400\n",
      "2130/2130 [==============================] - 1s 611us/step - loss: 179.7086 - coeff_determination: 0.6087 - val_loss: 60.1324 - val_coeff_determination: 0.8680\n",
      "Epoch 2/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 75.5442 - coeff_determination: 0.8329 - val_loss: 62.8660 - val_coeff_determination: 0.8400\n",
      "Epoch 3/400\n",
      "2130/2130 [==============================] - 0s 208us/step - loss: 86.0952 - coeff_determination: 0.8250 - val_loss: 177.2608 - val_coeff_determination: 0.8057\n",
      "Epoch 4/400\n",
      "2130/2130 [==============================] - 0s 200us/step - loss: 91.6905 - coeff_determination: 0.8272 - val_loss: 63.1282 - val_coeff_determination: 0.9067\n",
      "Epoch 5/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 177.3285 - coeff_determination: 0.7569 - val_loss: 56.4242 - val_coeff_determination: 0.9130\n",
      "Epoch 6/400\n",
      "2130/2130 [==============================] - 1s 235us/step - loss: 102.3040 - coeff_determination: 0.8130 - val_loss: 67.4588 - val_coeff_determination: 0.8406\n",
      "Epoch 7/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 80.6906 - coeff_determination: 0.8569 - val_loss: 108.6555 - val_coeff_determination: 0.7792\n",
      "Epoch 8/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 89.0153 - coeff_determination: 0.8308 - val_loss: 220.0552 - val_coeff_determination: 0.7541\n",
      "Epoch 9/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 72.9470 - coeff_determination: 0.8477 - val_loss: 108.0110 - val_coeff_determination: 0.8620\n",
      "Epoch 10/400\n",
      "2130/2130 [==============================] - 1s 244us/step - loss: 249.9495 - coeff_determination: 0.6589 - val_loss: 506.9669 - val_coeff_determination: 0.5656\n",
      "Epoch 11/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 148.8982 - coeff_determination: 0.8037 - val_loss: 58.8262 - val_coeff_determination: 0.9140\n",
      "Epoch 12/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 79.1400 - coeff_determination: 0.8633 - val_loss: 38.6368 - val_coeff_determination: 0.8937\n",
      "Epoch 13/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 68.5376 - coeff_determination: 0.8816 - val_loss: 55.3104 - val_coeff_determination: 0.8645\n",
      "Epoch 14/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 52.7605 - coeff_determination: 0.8982 - val_loss: 30.6619 - val_coeff_determination: 0.9309\n",
      "Epoch 15/400\n",
      "2130/2130 [==============================] - 1s 238us/step - loss: 116.9436 - coeff_determination: 0.8368 - val_loss: 196.3213 - val_coeff_determination: 0.7867\n",
      "Epoch 16/400\n",
      "2130/2130 [==============================] - 1s 240us/step - loss: 27.2226 - coeff_determination: 0.9076 - val_loss: 25.9436 - val_coeff_determination: 0.9248\n",
      "Epoch 17/400\n",
      "2130/2130 [==============================] - 1s 245us/step - loss: 185.2716 - coeff_determination: 0.7533 - val_loss: 368.6754 - val_coeff_determination: 0.5851\n",
      "Epoch 18/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 79.2935 - coeff_determination: 0.8567 - val_loss: 78.7948 - val_coeff_determination: 0.8810\n",
      "Epoch 19/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 50.5444 - coeff_determination: 0.8938 - val_loss: 44.5488 - val_coeff_determination: 0.9081\n",
      "Epoch 20/400\n",
      "2130/2130 [==============================] - 0s 199us/step - loss: 71.1121 - coeff_determination: 0.8814 - val_loss: 40.1560 - val_coeff_determination: 0.8981\n",
      "Epoch 21/400\n",
      "2130/2130 [==============================] - 0s 206us/step - loss: 71.2663 - coeff_determination: 0.8688 - val_loss: 84.5471 - val_coeff_determination: 0.8585\n",
      "Epoch 22/400\n",
      "2130/2130 [==============================] - 0s 210us/step - loss: 91.6658 - coeff_determination: 0.8629 - val_loss: 247.5596 - val_coeff_determination: 0.7278\n",
      "Epoch 23/400\n",
      "2130/2130 [==============================] - 0s 204us/step - loss: 90.8593 - coeff_determination: 0.8526 - val_loss: 33.0488 - val_coeff_determination: 0.9086\n",
      "Epoch 24/400\n",
      "2130/2130 [==============================] - 0s 214us/step - loss: 120.5716 - coeff_determination: 0.8505 - val_loss: 30.0232 - val_coeff_determination: 0.9024\n",
      "Epoch 25/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 33.3611 - coeff_determination: 0.9150 - val_loss: 28.7392 - val_coeff_determination: 0.9174\n",
      "Epoch 26/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 69.4041 - coeff_determination: 0.8655 - val_loss: 30.2391 - val_coeff_determination: 0.9150\n",
      "Epoch 27/400\n",
      "2130/2130 [==============================] - 1s 240us/step - loss: 33.2067 - coeff_determination: 0.9195 - val_loss: 95.7968 - val_coeff_determination: 0.8365\n",
      "Epoch 28/400\n",
      "2130/2130 [==============================] - 1s 241us/step - loss: 30.2504 - coeff_determination: 0.9317 - val_loss: 23.6590 - val_coeff_determination: 0.9240\n",
      "Epoch 29/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 85.2956 - coeff_determination: 0.8803 - val_loss: 44.9162 - val_coeff_determination: 0.8517\n",
      "Epoch 30/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 55.9979 - coeff_determination: 0.9057 - val_loss: 73.5723 - val_coeff_determination: 0.8678\n",
      "Epoch 31/400\n",
      "2130/2130 [==============================] - 0s 211us/step - loss: 38.8149 - coeff_determination: 0.9108 - val_loss: 45.5711 - val_coeff_determination: 0.8943\n",
      "Epoch 32/400\n",
      "2130/2130 [==============================] - 0s 215us/step - loss: 64.9298 - coeff_determination: 0.9200 - val_loss: 50.3506 - val_coeff_determination: 0.8967\n",
      "Epoch 33/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 86.7808 - coeff_determination: 0.8773 - val_loss: 98.2399 - val_coeff_determination: 0.8618\n",
      "Epoch 34/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 43.7684 - coeff_determination: 0.9110 - val_loss: 75.4656 - val_coeff_determination: 0.8298\n",
      "Epoch 35/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 43.6698 - coeff_determination: 0.9212 - val_loss: 34.6802 - val_coeff_determination: 0.8999\n",
      "Epoch 36/400\n",
      "2130/2130 [==============================] - 0s 208us/step - loss: 85.6323 - coeff_determination: 0.8747 - val_loss: 224.9311 - val_coeff_determination: 0.7571\n",
      "Epoch 37/400\n",
      "2130/2130 [==============================] - 0s 201us/step - loss: 52.3310 - coeff_determination: 0.9182 - val_loss: 25.0107 - val_coeff_determination: 0.9239\n",
      "Epoch 38/400\n",
      "2130/2130 [==============================] - 0s 210us/step - loss: 32.6118 - coeff_determination: 0.9234 - val_loss: 64.8251 - val_coeff_determination: 0.8595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 67.1333 - coeff_determination: 0.8835 - val_loss: 131.2863 - val_coeff_determination: 0.7954\n",
      "Epoch 40/400\n",
      "2130/2130 [==============================] - 0s 196us/step - loss: 72.4036 - coeff_determination: 0.8917 - val_loss: 184.2684 - val_coeff_determination: 0.7621\n",
      "Epoch 41/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 67.6583 - coeff_determination: 0.8938 - val_loss: 42.5240 - val_coeff_determination: 0.8721\n",
      "Epoch 42/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 95.5604 - coeff_determination: 0.8858 - val_loss: 153.6899 - val_coeff_determination: 0.8133\n",
      "Epoch 43/400\n",
      "2130/2130 [==============================] - 0s 205us/step - loss: 120.2085 - coeff_determination: 0.8520 - val_loss: 63.4563 - val_coeff_determination: 0.8710\n",
      "Epoch 44/400\n",
      "2130/2130 [==============================] - 0s 201us/step - loss: 58.8465 - coeff_determination: 0.8937 - val_loss: 29.9049 - val_coeff_determination: 0.8883\n",
      "Epoch 45/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 25.6348 - coeff_determination: 0.9369 - val_loss: 67.4563 - val_coeff_determination: 0.8618\n",
      "Epoch 46/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 62.8217 - coeff_determination: 0.8949 - val_loss: 130.8518 - val_coeff_determination: 0.7655\n",
      "Epoch 47/400\n",
      "2130/2130 [==============================] - 1s 247us/step - loss: 36.1431 - coeff_determination: 0.9262 - val_loss: 34.6507 - val_coeff_determination: 0.8752\n",
      "Epoch 48/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 42.1844 - coeff_determination: 0.9186 - val_loss: 38.7206 - val_coeff_determination: 0.8543\n",
      "Epoch 49/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 92.4316 - coeff_determination: 0.8908 - val_loss: 74.6843 - val_coeff_determination: 0.8248\n",
      "Epoch 50/400\n",
      "2130/2130 [==============================] - 1s 244us/step - loss: 34.7414 - coeff_determination: 0.9278 - val_loss: 58.0669 - val_coeff_determination: 0.8231\n",
      "Epoch 51/400\n",
      "2130/2130 [==============================] - 1s 242us/step - loss: 46.1078 - coeff_determination: 0.9202 - val_loss: 122.9435 - val_coeff_determination: 0.7828\n",
      "Epoch 52/400\n",
      "2130/2130 [==============================] - 1s 260us/step - loss: 43.1776 - coeff_determination: 0.9228 - val_loss: 38.7692 - val_coeff_determination: 0.8791\n",
      "Epoch 53/400\n",
      "2130/2130 [==============================] - 1s 252us/step - loss: 59.0099 - coeff_determination: 0.9133 - val_loss: 35.0665 - val_coeff_determination: 0.8792\n",
      "Epoch 54/400\n",
      "2130/2130 [==============================] - 1s 246us/step - loss: 39.4130 - coeff_determination: 0.9294 - val_loss: 85.5256 - val_coeff_determination: 0.8405\n",
      "Epoch 55/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 27.5982 - coeff_determination: 0.9421 - val_loss: 47.1071 - val_coeff_determination: 0.8800\n",
      "Epoch 56/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 106.7879 - coeff_determination: 0.8808 - val_loss: 48.3092 - val_coeff_determination: 0.8156\n",
      "Epoch 57/400\n",
      "2130/2130 [==============================] - 0s 215us/step - loss: 39.5436 - coeff_determination: 0.9193 - val_loss: 66.9579 - val_coeff_determination: 0.8304\n",
      "Epoch 58/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 19.5854 - coeff_determination: 0.9470 - val_loss: 68.1783 - val_coeff_determination: 0.8472\n",
      "Epoch 59/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 30.6622 - coeff_determination: 0.9443 - val_loss: 53.3192 - val_coeff_determination: 0.8765\n",
      "Epoch 60/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 110.6520 - coeff_determination: 0.8636 - val_loss: 317.0953 - val_coeff_determination: 0.6394\n",
      "Epoch 61/400\n",
      "2130/2130 [==============================] - 1s 256us/step - loss: 82.6096 - coeff_determination: 0.8855 - val_loss: 44.6548 - val_coeff_determination: 0.8746\n",
      "Epoch 62/400\n",
      "2130/2130 [==============================] - 0s 205us/step - loss: 51.8783 - coeff_determination: 0.9256 - val_loss: 68.6142 - val_coeff_determination: 0.8604\n",
      "Epoch 63/400\n",
      "2130/2130 [==============================] - 0s 214us/step - loss: 125.0671 - coeff_determination: 0.8586 - val_loss: 237.8293 - val_coeff_determination: 0.7280\n",
      "Epoch 64/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 100.1354 - coeff_determination: 0.8744 - val_loss: 105.7129 - val_coeff_determination: 0.7734\n",
      "Epoch 65/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 43.5574 - coeff_determination: 0.9087 - val_loss: 38.0675 - val_coeff_determination: 0.8729\n",
      "Epoch 66/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 56.0928 - coeff_determination: 0.9151 - val_loss: 39.3262 - val_coeff_determination: 0.8661\n",
      "Epoch 67/400\n",
      "2130/2130 [==============================] - 1s 242us/step - loss: 36.5303 - coeff_determination: 0.9335 - val_loss: 35.8829 - val_coeff_determination: 0.8758\n",
      "Epoch 68/400\n",
      "2130/2130 [==============================] - 1s 241us/step - loss: 56.4656 - coeff_determination: 0.9182 - val_loss: 57.7858 - val_coeff_determination: 0.8708\n",
      "Epoch 69/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 29.4467 - coeff_determination: 0.9353 - val_loss: 37.5600 - val_coeff_determination: 0.8722\n",
      "Epoch 70/400\n",
      "2130/2130 [==============================] - 1s 250us/step - loss: 19.7515 - coeff_determination: 0.9421 - val_loss: 38.8276 - val_coeff_determination: 0.8791\n",
      "Epoch 71/400\n",
      "2130/2130 [==============================] - 1s 265us/step - loss: 82.2653 - coeff_determination: 0.8903 - val_loss: 39.3338 - val_coeff_determination: 0.8699\n",
      "Epoch 72/400\n",
      "2130/2130 [==============================] - 1s 275us/step - loss: 59.5350 - coeff_determination: 0.9124 - val_loss: 55.5481 - val_coeff_determination: 0.8613\n",
      "Epoch 73/400\n",
      "2130/2130 [==============================] - 1s 302us/step - loss: 25.5247 - coeff_determination: 0.9383 - val_loss: 43.9244 - val_coeff_determination: 0.8444\n",
      "Epoch 74/400\n",
      "2130/2130 [==============================] - 1s 294us/step - loss: 25.2288 - coeff_determination: 0.9447 - val_loss: 40.6995 - val_coeff_determination: 0.8735\n",
      "Epoch 75/400\n",
      "2130/2130 [==============================] - 1s 279us/step - loss: 45.0484 - coeff_determination: 0.9218 - val_loss: 46.2445 - val_coeff_determination: 0.8537\n",
      "Epoch 76/400\n",
      "2130/2130 [==============================] - 1s 252us/step - loss: 62.6808 - coeff_determination: 0.9130 - val_loss: 60.1955 - val_coeff_determination: 0.8377\n",
      "Epoch 77/400\n",
      "2130/2130 [==============================] - 1s 271us/step - loss: 31.7573 - coeff_determination: 0.9395 - val_loss: 70.8451 - val_coeff_determination: 0.8528\n",
      "Epoch 78/400\n",
      "2130/2130 [==============================] - 1s 241us/step - loss: 19.6433 - coeff_determination: 0.9475 - val_loss: 47.0013 - val_coeff_determination: 0.8558\n",
      "Epoch 79/400\n",
      "2130/2130 [==============================] - 1s 258us/step - loss: 29.6365 - coeff_determination: 0.9414 - val_loss: 59.7188 - val_coeff_determination: 0.8311\n",
      "Epoch 80/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 82.2085 - coeff_determination: 0.8941 - val_loss: 174.3186 - val_coeff_determination: 0.7547\n",
      "Epoch 81/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 37.6781 - coeff_determination: 0.9347 - val_loss: 40.7580 - val_coeff_determination: 0.8513\n",
      "Epoch 82/400\n",
      "2130/2130 [==============================] - 0s 217us/step - loss: 58.7678 - coeff_determination: 0.9098 - val_loss: 29.4443 - val_coeff_determination: 0.8885\n",
      "Epoch 83/400\n",
      "2130/2130 [==============================] - 0s 202us/step - loss: 35.9003 - coeff_determination: 0.9389 - val_loss: 50.7701 - val_coeff_determination: 0.8602\n",
      "Epoch 84/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 25.6139 - coeff_determination: 0.9505 - val_loss: 36.7436 - val_coeff_determination: 0.8659\n",
      "Epoch 85/400\n",
      "2130/2130 [==============================] - 1s 254us/step - loss: 42.7681 - coeff_determination: 0.9301 - val_loss: 51.8146 - val_coeff_determination: 0.8650\n",
      "Epoch 86/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 1s 244us/step - loss: 26.6102 - coeff_determination: 0.9478 - val_loss: 76.5594 - val_coeff_determination: 0.8356\n",
      "Epoch 87/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 70.3040 - coeff_determination: 0.9114 - val_loss: 45.1216 - val_coeff_determination: 0.8348\n",
      "Epoch 88/400\n",
      "2130/2130 [==============================] - 1s 266us/step - loss: 38.5460 - coeff_determination: 0.9289 - val_loss: 41.3845 - val_coeff_determination: 0.8725\n",
      "Epoch 89/400\n",
      "2130/2130 [==============================] - 1s 258us/step - loss: 29.8007 - coeff_determination: 0.9426 - val_loss: 39.3949 - val_coeff_determination: 0.8582\n",
      "Epoch 90/400\n",
      "2130/2130 [==============================] - 1s 252us/step - loss: 68.6550 - coeff_determination: 0.9164 - val_loss: 65.7041 - val_coeff_determination: 0.8085\n",
      "Epoch 91/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 39.3135 - coeff_determination: 0.9341 - val_loss: 92.5654 - val_coeff_determination: 0.7963\n",
      "Epoch 92/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 49.3405 - coeff_determination: 0.9309 - val_loss: 294.2931 - val_coeff_determination: 0.6284\n",
      "Epoch 93/400\n",
      "2130/2130 [==============================] - 1s 245us/step - loss: 69.7484 - coeff_determination: 0.9085 - val_loss: 55.6530 - val_coeff_determination: 0.8382\n",
      "Epoch 94/400\n",
      "2130/2130 [==============================] - 1s 235us/step - loss: 55.3990 - coeff_determination: 0.9176 - val_loss: 125.2378 - val_coeff_determination: 0.7821\n",
      "Epoch 95/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 49.4282 - coeff_determination: 0.9227 - val_loss: 67.2010 - val_coeff_determination: 0.8364\n",
      "Epoch 96/400\n",
      "2130/2130 [==============================] - 1s 245us/step - loss: 32.5711 - coeff_determination: 0.9456 - val_loss: 62.5242 - val_coeff_determination: 0.8203\n",
      "Epoch 97/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 42.9762 - coeff_determination: 0.9283 - val_loss: 44.5645 - val_coeff_determination: 0.8497\n",
      "Epoch 98/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 48.9383 - coeff_determination: 0.9328 - val_loss: 116.8229 - val_coeff_determination: 0.7996\n",
      "Epoch 99/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 62.4667 - coeff_determination: 0.9119 - val_loss: 39.4773 - val_coeff_determination: 0.8639\n",
      "Epoch 100/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 20.6504 - coeff_determination: 0.9472 - val_loss: 128.2198 - val_coeff_determination: 0.7687\n",
      "Epoch 101/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 22.5674 - coeff_determination: 0.9443 - val_loss: 55.5280 - val_coeff_determination: 0.8258\n",
      "Epoch 102/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 29.6478 - coeff_determination: 0.9471 - val_loss: 66.4188 - val_coeff_determination: 0.7936\n",
      "Epoch 103/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 33.5352 - coeff_determination: 0.9327 - val_loss: 98.4794 - val_coeff_determination: 0.8269\n",
      "Epoch 104/400\n",
      "2130/2130 [==============================] - 0s 210us/step - loss: 50.1863 - coeff_determination: 0.9118 - val_loss: 174.0289 - val_coeff_determination: 0.7061\n",
      "Epoch 105/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 50.9406 - coeff_determination: 0.9319 - val_loss: 78.8986 - val_coeff_determination: 0.8183\n",
      "Epoch 106/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 53.2524 - coeff_determination: 0.9086 - val_loss: 106.2162 - val_coeff_determination: 0.7686\n",
      "Epoch 107/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 28.0279 - coeff_determination: 0.9498 - val_loss: 73.6185 - val_coeff_determination: 0.8190\n",
      "Epoch 108/400\n",
      "2130/2130 [==============================] - 0s 204us/step - loss: 44.6629 - coeff_determination: 0.9269 - val_loss: 122.9476 - val_coeff_determination: 0.7769\n",
      "Epoch 109/400\n",
      "2130/2130 [==============================] - 0s 211us/step - loss: 35.8952 - coeff_determination: 0.9382 - val_loss: 54.3088 - val_coeff_determination: 0.8183\n",
      "Epoch 110/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 36.1824 - coeff_determination: 0.9396 - val_loss: 68.3436 - val_coeff_determination: 0.8055\n",
      "Epoch 111/400\n",
      "2130/2130 [==============================] - 1s 247us/step - loss: 82.0160 - coeff_determination: 0.8866 - val_loss: 142.4769 - val_coeff_determination: 0.7488\n",
      "Epoch 112/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 39.7007 - coeff_determination: 0.9263 - val_loss: 103.8889 - val_coeff_determination: 0.7679\n",
      "Epoch 113/400\n",
      "2130/2130 [==============================] - 1s 254us/step - loss: 62.2358 - coeff_determination: 0.9012 - val_loss: 100.7813 - val_coeff_determination: 0.7490\n",
      "Epoch 114/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 39.5490 - coeff_determination: 0.9358 - val_loss: 108.5429 - val_coeff_determination: 0.7559\n",
      "Epoch 115/400\n",
      "2130/2130 [==============================] - 1s 235us/step - loss: 43.7878 - coeff_determination: 0.9231 - val_loss: 176.9042 - val_coeff_determination: 0.7097\n",
      "Epoch 116/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 43.8160 - coeff_determination: 0.9110 - val_loss: 53.1315 - val_coeff_determination: 0.8285\n",
      "Epoch 117/400\n",
      "2130/2130 [==============================] - 0s 206us/step - loss: 15.1818 - coeff_determination: 0.9606 - val_loss: 52.3928 - val_coeff_determination: 0.8177\n",
      "Epoch 118/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 26.8763 - coeff_determination: 0.9511 - val_loss: 59.5806 - val_coeff_determination: 0.8332\n",
      "Epoch 119/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 24.0520 - coeff_determination: 0.9456 - val_loss: 38.9829 - val_coeff_determination: 0.8536\n",
      "Epoch 120/400\n",
      "2130/2130 [==============================] - 0s 230us/step - loss: 25.4742 - coeff_determination: 0.9495 - val_loss: 108.0323 - val_coeff_determination: 0.7561\n",
      "Epoch 121/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 22.3009 - coeff_determination: 0.9412 - val_loss: 67.5374 - val_coeff_determination: 0.8211\n",
      "Epoch 122/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 22.8071 - coeff_determination: 0.9558 - val_loss: 49.0153 - val_coeff_determination: 0.8158\n",
      "Epoch 123/400\n",
      "2130/2130 [==============================] - 1s 238us/step - loss: 34.0258 - coeff_determination: 0.9461 - val_loss: 83.6761 - val_coeff_determination: 0.7682\n",
      "Epoch 124/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 26.0104 - coeff_determination: 0.9436 - val_loss: 50.2923 - val_coeff_determination: 0.8067\n",
      "Epoch 125/400\n",
      "2130/2130 [==============================] - 1s 241us/step - loss: 44.0345 - coeff_determination: 0.9361 - val_loss: 121.0715 - val_coeff_determination: 0.7211\n",
      "Epoch 126/400\n",
      "2130/2130 [==============================] - 0s 217us/step - loss: 39.1596 - coeff_determination: 0.9344 - val_loss: 61.8501 - val_coeff_determination: 0.7946\n",
      "Epoch 127/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 40.7566 - coeff_determination: 0.9307 - val_loss: 68.3366 - val_coeff_determination: 0.8132\n",
      "Epoch 128/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 38.6558 - coeff_determination: 0.9408 - val_loss: 49.3235 - val_coeff_determination: 0.8198\n",
      "Epoch 129/400\n",
      "2130/2130 [==============================] - 1s 238us/step - loss: 69.8872 - coeff_determination: 0.9078 - val_loss: 61.2478 - val_coeff_determination: 0.8209\n",
      "Epoch 130/400\n",
      "2130/2130 [==============================] - 1s 245us/step - loss: 30.4916 - coeff_determination: 0.9526 - val_loss: 62.5709 - val_coeff_determination: 0.7983\n",
      "Epoch 131/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 32.4024 - coeff_determination: 0.9375 - val_loss: 51.4428 - val_coeff_determination: 0.8207\n",
      "Epoch 132/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 28.2625 - coeff_determination: 0.9465 - val_loss: 70.4584 - val_coeff_determination: 0.7841\n",
      "Epoch 133/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 1s 235us/step - loss: 32.6993 - coeff_determination: 0.9485 - val_loss: 60.5207 - val_coeff_determination: 0.7907\n",
      "Epoch 134/400\n",
      "2130/2130 [==============================] - 0s 219us/step - loss: 32.3390 - coeff_determination: 0.9422 - val_loss: 96.9479 - val_coeff_determination: 0.7678\n",
      "Epoch 135/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 57.9643 - coeff_determination: 0.9125 - val_loss: 174.0304 - val_coeff_determination: 0.6987\n",
      "Epoch 136/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 27.8689 - coeff_determination: 0.9341 - val_loss: 58.7019 - val_coeff_determination: 0.8031\n",
      "Epoch 137/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 42.8729 - coeff_determination: 0.9364 - val_loss: 69.5073 - val_coeff_determination: 0.7867\n",
      "Epoch 138/400\n",
      "2130/2130 [==============================] - 0s 205us/step - loss: 34.8442 - coeff_determination: 0.9468 - val_loss: 77.6386 - val_coeff_determination: 0.7752\n",
      "Epoch 139/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 27.1811 - coeff_determination: 0.9434 - val_loss: 77.9176 - val_coeff_determination: 0.7830\n",
      "Epoch 140/400\n",
      "2130/2130 [==============================] - 0s 219us/step - loss: 29.6505 - coeff_determination: 0.9541 - val_loss: 57.7224 - val_coeff_determination: 0.7871\n",
      "Epoch 141/400\n",
      "2130/2130 [==============================] - 1s 254us/step - loss: 19.3462 - coeff_determination: 0.9555 - val_loss: 48.8018 - val_coeff_determination: 0.8064\n",
      "Epoch 142/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 16.8192 - coeff_determination: 0.9635 - val_loss: 63.9173 - val_coeff_determination: 0.7928\n",
      "Epoch 143/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 30.6096 - coeff_determination: 0.9479 - val_loss: 55.6962 - val_coeff_determination: 0.8086\n",
      "Epoch 144/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 26.6447 - coeff_determination: 0.9551 - val_loss: 141.2004 - val_coeff_determination: 0.7202\n",
      "Epoch 145/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 36.8650 - coeff_determination: 0.9415 - val_loss: 57.4775 - val_coeff_determination: 0.8004\n",
      "Epoch 146/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 43.4250 - coeff_determination: 0.9431 - val_loss: 127.0313 - val_coeff_determination: 0.7114\n",
      "Epoch 147/400\n",
      "2130/2130 [==============================] - 0s 219us/step - loss: 47.0786 - coeff_determination: 0.9346 - val_loss: 58.8554 - val_coeff_determination: 0.7765\n",
      "Epoch 148/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 27.2858 - coeff_determination: 0.9531 - val_loss: 62.8886 - val_coeff_determination: 0.7872\n",
      "Epoch 149/400\n",
      "2130/2130 [==============================] - 0s 214us/step - loss: 25.9040 - coeff_determination: 0.9540 - val_loss: 93.9996 - val_coeff_determination: 0.7629\n",
      "Epoch 150/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 36.1409 - coeff_determination: 0.9378 - val_loss: 64.5181 - val_coeff_determination: 0.7799\n",
      "Epoch 151/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 33.1231 - coeff_determination: 0.9436 - val_loss: 74.4970 - val_coeff_determination: 0.7777\n",
      "Epoch 152/400\n",
      "2130/2130 [==============================] - 0s 204us/step - loss: 26.8813 - coeff_determination: 0.9516 - val_loss: 55.2697 - val_coeff_determination: 0.7837\n",
      "Epoch 153/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 57.1944 - coeff_determination: 0.9272 - val_loss: 59.6296 - val_coeff_determination: 0.7937\n",
      "Epoch 154/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 19.1776 - coeff_determination: 0.9581 - val_loss: 65.8481 - val_coeff_determination: 0.8096\n",
      "Epoch 155/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 13.2258 - coeff_determination: 0.9662 - val_loss: 60.4887 - val_coeff_determination: 0.7987\n",
      "Epoch 156/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 22.9621 - coeff_determination: 0.9665 - val_loss: 69.5852 - val_coeff_determination: 0.7790\n",
      "Epoch 157/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 14.1286 - coeff_determination: 0.9698 - val_loss: 75.1884 - val_coeff_determination: 0.7564\n",
      "Epoch 158/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 34.6640 - coeff_determination: 0.9477 - val_loss: 112.6814 - val_coeff_determination: 0.7104\n",
      "Epoch 159/400\n",
      "2130/2130 [==============================] - 1s 253us/step - loss: 18.2852 - coeff_determination: 0.9596 - val_loss: 101.4701 - val_coeff_determination: 0.7502\n",
      "Epoch 160/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 46.0703 - coeff_determination: 0.9432 - val_loss: 217.6364 - val_coeff_determination: 0.6623\n",
      "Epoch 161/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 33.1886 - coeff_determination: 0.9495 - val_loss: 59.8879 - val_coeff_determination: 0.7824\n",
      "Epoch 162/400\n",
      "2130/2130 [==============================] - 0s 224us/step - loss: 23.6916 - coeff_determination: 0.9582 - val_loss: 104.6974 - val_coeff_determination: 0.7401\n",
      "Epoch 163/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 17.2561 - coeff_determination: 0.9620 - val_loss: 89.2090 - val_coeff_determination: 0.7702\n",
      "Epoch 164/400\n",
      "2130/2130 [==============================] - 1s 265us/step - loss: 11.3734 - coeff_determination: 0.9673 - val_loss: 57.0403 - val_coeff_determination: 0.7778\n",
      "Epoch 165/400\n",
      "2130/2130 [==============================] - 1s 260us/step - loss: 61.6164 - coeff_determination: 0.9303 - val_loss: 117.8816 - val_coeff_determination: 0.7324\n",
      "Epoch 166/400\n",
      "2130/2130 [==============================] - 0s 212us/step - loss: 18.0269 - coeff_determination: 0.9650 - val_loss: 93.1144 - val_coeff_determination: 0.7476\n",
      "Epoch 167/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 22.7000 - coeff_determination: 0.9622 - val_loss: 97.6286 - val_coeff_determination: 0.7710\n",
      "Epoch 168/400\n",
      "2130/2130 [==============================] - 1s 244us/step - loss: 25.8987 - coeff_determination: 0.9558 - val_loss: 96.5524 - val_coeff_determination: 0.7587\n",
      "Epoch 169/400\n",
      "2130/2130 [==============================] - 1s 244us/step - loss: 32.0510 - coeff_determination: 0.9457 - val_loss: 132.1426 - val_coeff_determination: 0.7195\n",
      "Epoch 170/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 21.6445 - coeff_determination: 0.9617 - val_loss: 93.9149 - val_coeff_determination: 0.7569\n",
      "Epoch 171/400\n",
      "2130/2130 [==============================] - 1s 258us/step - loss: 44.2647 - coeff_determination: 0.9443 - val_loss: 76.0802 - val_coeff_determination: 0.7620\n",
      "Epoch 172/400\n",
      "2130/2130 [==============================] - 1s 247us/step - loss: 25.4653 - coeff_determination: 0.9588 - val_loss: 85.8949 - val_coeff_determination: 0.7654\n",
      "Epoch 173/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 22.1865 - coeff_determination: 0.9603 - val_loss: 65.3130 - val_coeff_determination: 0.7678\n",
      "Epoch 174/400\n",
      "2130/2130 [==============================] - 1s 251us/step - loss: 56.4801 - coeff_determination: 0.9185 - val_loss: 244.2732 - val_coeff_determination: 0.6360\n",
      "Epoch 175/400\n",
      "2130/2130 [==============================] - 1s 249us/step - loss: 46.6665 - coeff_determination: 0.9353 - val_loss: 58.4531 - val_coeff_determination: 0.7852\n",
      "Epoch 176/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 28.4725 - coeff_determination: 0.9580 - val_loss: 86.9988 - val_coeff_determination: 0.7644\n",
      "Epoch 177/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 74.1291 - coeff_determination: 0.9048 - val_loss: 231.5687 - val_coeff_determination: 0.6555\n",
      "Epoch 178/400\n",
      "2130/2130 [==============================] - 0s 219us/step - loss: 46.7162 - coeff_determination: 0.9482 - val_loss: 59.0420 - val_coeff_determination: 0.7824\n",
      "Epoch 179/400\n",
      "2130/2130 [==============================] - 0s 219us/step - loss: 25.6260 - coeff_determination: 0.9548 - val_loss: 57.6916 - val_coeff_determination: 0.7790\n",
      "Epoch 180/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 1s 238us/step - loss: 22.2265 - coeff_determination: 0.9605 - val_loss: 57.2719 - val_coeff_determination: 0.7931\n",
      "Epoch 181/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 19.1999 - coeff_determination: 0.9659 - val_loss: 83.8732 - val_coeff_determination: 0.7643\n",
      "Epoch 182/400\n",
      "2130/2130 [==============================] - 1s 261us/step - loss: 25.7889 - coeff_determination: 0.9512 - val_loss: 83.5108 - val_coeff_determination: 0.7217\n",
      "Epoch 183/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 12.2469 - coeff_determination: 0.9612 - val_loss: 49.9696 - val_coeff_determination: 0.8111\n",
      "Epoch 184/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 21.8323 - coeff_determination: 0.9601 - val_loss: 60.8454 - val_coeff_determination: 0.7823\n",
      "Epoch 185/400\n",
      "2130/2130 [==============================] - 0s 219us/step - loss: 13.4444 - coeff_determination: 0.9721 - val_loss: 100.5559 - val_coeff_determination: 0.7505\n",
      "Epoch 186/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 19.5721 - coeff_determination: 0.9591 - val_loss: 56.4444 - val_coeff_determination: 0.7959\n",
      "Epoch 187/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 18.9698 - coeff_determination: 0.9663 - val_loss: 71.6360 - val_coeff_determination: 0.7670\n",
      "Epoch 188/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 18.1241 - coeff_determination: 0.9662 - val_loss: 112.2632 - val_coeff_determination: 0.7714\n",
      "Epoch 189/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 29.6080 - coeff_determination: 0.9617 - val_loss: 81.6422 - val_coeff_determination: 0.7643\n",
      "Epoch 190/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 12.2030 - coeff_determination: 0.9716 - val_loss: 110.9401 - val_coeff_determination: 0.7265\n",
      "Epoch 191/400\n",
      "2130/2130 [==============================] - 1s 249us/step - loss: 33.6649 - coeff_determination: 0.9526 - val_loss: 73.9480 - val_coeff_determination: 0.7705\n",
      "Epoch 192/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 52.2420 - coeff_determination: 0.9252 - val_loss: 63.2095 - val_coeff_determination: 0.7792\n",
      "Epoch 193/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 23.9211 - coeff_determination: 0.9520 - val_loss: 91.6529 - val_coeff_determination: 0.7467\n",
      "Epoch 194/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 13.8491 - coeff_determination: 0.9714 - val_loss: 56.6301 - val_coeff_determination: 0.7812\n",
      "Epoch 195/400\n",
      "2130/2130 [==============================] - 1s 260us/step - loss: 38.5596 - coeff_determination: 0.9540 - val_loss: 89.2457 - val_coeff_determination: 0.7434\n",
      "Epoch 196/400\n",
      "2130/2130 [==============================] - 1s 245us/step - loss: 40.7583 - coeff_determination: 0.9601 - val_loss: 68.4298 - val_coeff_determination: 0.7843\n",
      "Epoch 197/400\n",
      "2130/2130 [==============================] - 1s 242us/step - loss: 31.9089 - coeff_determination: 0.9564 - val_loss: 62.1690 - val_coeff_determination: 0.7890\n",
      "Epoch 198/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 30.9568 - coeff_determination: 0.9391 - val_loss: 140.7728 - val_coeff_determination: 0.6851\n",
      "Epoch 199/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 45.4931 - coeff_determination: 0.9222 - val_loss: 157.1143 - val_coeff_determination: 0.6832\n",
      "Epoch 200/400\n",
      "2130/2130 [==============================] - 0s 212us/step - loss: 24.8243 - coeff_determination: 0.9544 - val_loss: 98.2586 - val_coeff_determination: 0.7372\n",
      "Epoch 201/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 15.5588 - coeff_determination: 0.9652 - val_loss: 69.4808 - val_coeff_determination: 0.7666\n",
      "Epoch 202/400\n",
      "2130/2130 [==============================] - 1s 238us/step - loss: 21.5514 - coeff_determination: 0.9613 - val_loss: 151.4093 - val_coeff_determination: 0.6775\n",
      "Epoch 203/400\n",
      "2130/2130 [==============================] - 0s 214us/step - loss: 17.2718 - coeff_determination: 0.9664 - val_loss: 57.6717 - val_coeff_determination: 0.8008\n",
      "Epoch 204/400\n",
      "2130/2130 [==============================] - 0s 206us/step - loss: 17.6740 - coeff_determination: 0.9640 - val_loss: 57.4770 - val_coeff_determination: 0.7866\n",
      "Epoch 205/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 13.9523 - coeff_determination: 0.9710 - val_loss: 67.7599 - val_coeff_determination: 0.7623\n",
      "Epoch 206/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 27.9200 - coeff_determination: 0.9605 - val_loss: 70.0384 - val_coeff_determination: 0.7537\n",
      "Epoch 207/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 18.8968 - coeff_determination: 0.9598 - val_loss: 57.3427 - val_coeff_determination: 0.7983\n",
      "Epoch 208/400\n",
      "2130/2130 [==============================] - 0s 217us/step - loss: 38.1576 - coeff_determination: 0.9412 - val_loss: 125.3404 - val_coeff_determination: 0.7329\n",
      "Epoch 209/400\n",
      "2130/2130 [==============================] - 0s 235us/step - loss: 27.7150 - coeff_determination: 0.9501 - val_loss: 161.0970 - val_coeff_determination: 0.6956\n",
      "Epoch 210/400\n",
      "2130/2130 [==============================] - 1s 251us/step - loss: 33.8291 - coeff_determination: 0.9437 - val_loss: 83.6502 - val_coeff_determination: 0.7716\n",
      "Epoch 211/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 17.3138 - coeff_determination: 0.9671 - val_loss: 81.4183 - val_coeff_determination: 0.7693\n",
      "Epoch 212/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 17.0858 - coeff_determination: 0.9652 - val_loss: 69.6185 - val_coeff_determination: 0.7758\n",
      "Epoch 213/400\n",
      "2130/2130 [==============================] - 0s 214us/step - loss: 15.0188 - coeff_determination: 0.9682 - val_loss: 57.3157 - val_coeff_determination: 0.7697\n",
      "Epoch 214/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 13.4711 - coeff_determination: 0.9733 - val_loss: 65.9430 - val_coeff_determination: 0.7762\n",
      "Epoch 215/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 17.3164 - coeff_determination: 0.9684 - val_loss: 163.1270 - val_coeff_determination: 0.6947\n",
      "Epoch 216/400\n",
      "2130/2130 [==============================] - 0s 205us/step - loss: 42.3594 - coeff_determination: 0.9381 - val_loss: 119.4534 - val_coeff_determination: 0.6671\n",
      "Epoch 217/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 26.6138 - coeff_determination: 0.9321 - val_loss: 66.9411 - val_coeff_determination: 0.8094\n",
      "Epoch 218/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 22.5639 - coeff_determination: 0.9474 - val_loss: 111.2193 - val_coeff_determination: 0.7370\n",
      "Epoch 219/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 28.0609 - coeff_determination: 0.9501 - val_loss: 64.9819 - val_coeff_determination: 0.7561\n",
      "Epoch 220/400\n",
      "2130/2130 [==============================] - 1s 256us/step - loss: 34.0115 - coeff_determination: 0.9480 - val_loss: 59.3707 - val_coeff_determination: 0.7678\n",
      "Epoch 221/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 11.6356 - coeff_determination: 0.9694 - val_loss: 50.1603 - val_coeff_determination: 0.8018\n",
      "Epoch 222/400\n",
      "2130/2130 [==============================] - 1s 251us/step - loss: 24.9526 - coeff_determination: 0.9558 - val_loss: 116.0793 - val_coeff_determination: 0.7186\n",
      "Epoch 223/400\n",
      "2130/2130 [==============================] - 1s 272us/step - loss: 15.9219 - coeff_determination: 0.9652 - val_loss: 71.7765 - val_coeff_determination: 0.8115\n",
      "Epoch 224/400\n",
      "2130/2130 [==============================] - 1s 240us/step - loss: 42.6540 - coeff_determination: 0.9584 - val_loss: 197.9243 - val_coeff_determination: 0.6269\n",
      "Epoch 225/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 47.2131 - coeff_determination: 0.9308 - val_loss: 70.5204 - val_coeff_determination: 0.7748\n",
      "Epoch 226/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 25.9460 - coeff_determination: 0.9607 - val_loss: 53.3424 - val_coeff_determination: 0.7852\n",
      "Epoch 227/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 0s 225us/step - loss: 39.4181 - coeff_determination: 0.9423 - val_loss: 63.9465 - val_coeff_determination: 0.7669\n",
      "Epoch 228/400\n",
      "2130/2130 [==============================] - 0s 208us/step - loss: 22.4130 - coeff_determination: 0.9624 - val_loss: 99.6078 - val_coeff_determination: 0.7494\n",
      "Epoch 229/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 20.0328 - coeff_determination: 0.9543 - val_loss: 65.6156 - val_coeff_determination: 0.7559\n",
      "Epoch 230/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 39.4613 - coeff_determination: 0.9401 - val_loss: 49.7384 - val_coeff_determination: 0.7957\n",
      "Epoch 231/400\n",
      "2130/2130 [==============================] - 0s 225us/step - loss: 25.6021 - coeff_determination: 0.9582 - val_loss: 134.2016 - val_coeff_determination: 0.7162\n",
      "Epoch 232/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 28.9934 - coeff_determination: 0.9526 - val_loss: 70.4562 - val_coeff_determination: 0.7705\n",
      "Epoch 233/400\n",
      "2130/2130 [==============================] - 1s 245us/step - loss: 11.4113 - coeff_determination: 0.9705 - val_loss: 78.9553 - val_coeff_determination: 0.7809\n",
      "Epoch 234/400\n",
      "2130/2130 [==============================] - 1s 238us/step - loss: 17.4900 - coeff_determination: 0.9706 - val_loss: 93.8380 - val_coeff_determination: 0.7535\n",
      "Epoch 235/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 14.9996 - coeff_determination: 0.9699 - val_loss: 62.8378 - val_coeff_determination: 0.7718\n",
      "Epoch 236/400\n",
      "2130/2130 [==============================] - 0s 217us/step - loss: 17.9714 - coeff_determination: 0.9719 - val_loss: 66.9466 - val_coeff_determination: 0.7712\n",
      "Epoch 237/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 14.4064 - coeff_determination: 0.9698 - val_loss: 64.3460 - val_coeff_determination: 0.7690\n",
      "Epoch 238/400\n",
      "2130/2130 [==============================] - 1s 235us/step - loss: 8.7594 - coeff_determination: 0.9779 - val_loss: 72.5531 - val_coeff_determination: 0.7497\n",
      "Epoch 239/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 8.0323 - coeff_determination: 0.9795 - val_loss: 85.1297 - val_coeff_determination: 0.7416\n",
      "Epoch 240/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 15.0235 - coeff_determination: 0.9698 - val_loss: 51.7259 - val_coeff_determination: 0.8451\n",
      "Epoch 241/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 16.7834 - coeff_determination: 0.9565 - val_loss: 144.6366 - val_coeff_determination: 0.6901\n",
      "Epoch 242/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 48.9533 - coeff_determination: 0.9313 - val_loss: 58.6822 - val_coeff_determination: 0.7654\n",
      "Epoch 243/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 25.1360 - coeff_determination: 0.9528 - val_loss: 84.0744 - val_coeff_determination: 0.7315\n",
      "Epoch 244/400\n",
      "2130/2130 [==============================] - 0s 215us/step - loss: 17.9050 - coeff_determination: 0.9599 - val_loss: 71.2754 - val_coeff_determination: 0.7881\n",
      "Epoch 245/400\n",
      "2130/2130 [==============================] - 0s 229us/step - loss: 11.5397 - coeff_determination: 0.9755 - val_loss: 165.8977 - val_coeff_determination: 0.6819\n",
      "Epoch 246/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 23.6396 - coeff_determination: 0.9609 - val_loss: 116.6975 - val_coeff_determination: 0.7229\n",
      "Epoch 247/400\n",
      "2130/2130 [==============================] - 0s 217us/step - loss: 24.0534 - coeff_determination: 0.9556 - val_loss: 76.8214 - val_coeff_determination: 0.7572\n",
      "Epoch 248/400\n",
      "2130/2130 [==============================] - 0s 213us/step - loss: 16.6103 - coeff_determination: 0.9679 - val_loss: 64.1928 - val_coeff_determination: 0.7953\n",
      "Epoch 249/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 22.7461 - coeff_determination: 0.9660 - val_loss: 93.7351 - val_coeff_determination: 0.7755\n",
      "Epoch 250/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 12.1839 - coeff_determination: 0.9726 - val_loss: 85.8514 - val_coeff_determination: 0.7651\n",
      "Epoch 251/400\n",
      "2130/2130 [==============================] - 0s 227us/step - loss: 10.2275 - coeff_determination: 0.9748 - val_loss: 78.2393 - val_coeff_determination: 0.7724\n",
      "Epoch 252/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 9.1498 - coeff_determination: 0.9705 - val_loss: 62.9722 - val_coeff_determination: 0.7941\n",
      "Epoch 253/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 21.0613 - coeff_determination: 0.9512 - val_loss: 48.0374 - val_coeff_determination: 0.8117\n",
      "Epoch 254/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 19.2851 - coeff_determination: 0.9545 - val_loss: 98.7685 - val_coeff_determination: 0.7353\n",
      "Epoch 255/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 20.2812 - coeff_determination: 0.9534 - val_loss: 93.2867 - val_coeff_determination: 0.7543\n",
      "Epoch 256/400\n",
      "2130/2130 [==============================] - 1s 288us/step - loss: 28.1055 - coeff_determination: 0.9571 - val_loss: 48.3526 - val_coeff_determination: 0.8053\n",
      "Epoch 257/400\n",
      "2130/2130 [==============================] - 1s 272us/step - loss: 49.2492 - coeff_determination: 0.9460 - val_loss: 115.4592 - val_coeff_determination: 0.7429\n",
      "Epoch 258/400\n",
      "2130/2130 [==============================] - 1s 283us/step - loss: 18.8741 - coeff_determination: 0.9626 - val_loss: 81.1898 - val_coeff_determination: 0.7597\n",
      "Epoch 259/400\n",
      "2130/2130 [==============================] - 1s 254us/step - loss: 65.1130 - coeff_determination: 0.9232 - val_loss: 88.8171 - val_coeff_determination: 0.7201\n",
      "Epoch 260/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 48.1119 - coeff_determination: 0.9446 - val_loss: 76.4091 - val_coeff_determination: 0.7699\n",
      "Epoch 261/400\n",
      "2130/2130 [==============================] - 1s 253us/step - loss: 25.5572 - coeff_determination: 0.9610 - val_loss: 88.4400 - val_coeff_determination: 0.7540\n",
      "Epoch 262/400\n",
      "2130/2130 [==============================] - 1s 258us/step - loss: 12.6233 - coeff_determination: 0.9686 - val_loss: 61.8032 - val_coeff_determination: 0.7578\n",
      "Epoch 263/400\n",
      "2130/2130 [==============================] - 1s 261us/step - loss: 18.5015 - coeff_determination: 0.9657 - val_loss: 63.3938 - val_coeff_determination: 0.7828\n",
      "Epoch 264/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 24.2772 - coeff_determination: 0.9605 - val_loss: 61.4703 - val_coeff_determination: 0.7562\n",
      "Epoch 265/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 22.6848 - coeff_determination: 0.9679 - val_loss: 81.6232 - val_coeff_determination: 0.7310\n",
      "Epoch 266/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 28.7904 - coeff_determination: 0.9585 - val_loss: 229.1323 - val_coeff_determination: 0.6196\n",
      "Epoch 267/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 38.1851 - coeff_determination: 0.9475 - val_loss: 87.8268 - val_coeff_determination: 0.7443\n",
      "Epoch 268/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 12.4802 - coeff_determination: 0.9722 - val_loss: 67.1272 - val_coeff_determination: 0.7717\n",
      "Epoch 269/400\n",
      "2130/2130 [==============================] - 1s 270us/step - loss: 19.0275 - coeff_determination: 0.9716 - val_loss: 106.5225 - val_coeff_determination: 0.7239\n",
      "Epoch 270/400\n",
      "2130/2130 [==============================] - 1s 240us/step - loss: 10.7888 - coeff_determination: 0.9764 - val_loss: 65.6855 - val_coeff_determination: 0.7663\n",
      "Epoch 271/400\n",
      "2130/2130 [==============================] - 1s 240us/step - loss: 11.6763 - coeff_determination: 0.9758 - val_loss: 66.6420 - val_coeff_determination: 0.7552\n",
      "Epoch 272/400\n",
      "2130/2130 [==============================] - 1s 248us/step - loss: 30.9389 - coeff_determination: 0.9624 - val_loss: 64.7103 - val_coeff_determination: 0.7817\n",
      "Epoch 273/400\n",
      "2130/2130 [==============================] - 1s 242us/step - loss: 22.2492 - coeff_determination: 0.9619 - val_loss: 60.7208 - val_coeff_determination: 0.7592\n",
      "Epoch 274/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 1s 243us/step - loss: 38.3938 - coeff_determination: 0.9490 - val_loss: 69.3086 - val_coeff_determination: 0.7596\n",
      "Epoch 275/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 9.1521 - coeff_determination: 0.9792 - val_loss: 64.4540 - val_coeff_determination: 0.7739\n",
      "Epoch 276/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 9.8945 - coeff_determination: 0.9765 - val_loss: 77.8896 - val_coeff_determination: 0.7595\n",
      "Epoch 277/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 9.6822 - coeff_determination: 0.9781 - val_loss: 57.6350 - val_coeff_determination: 0.7890\n",
      "Epoch 278/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 12.4881 - coeff_determination: 0.9738 - val_loss: 77.1130 - val_coeff_determination: 0.7628\n",
      "Epoch 279/400\n",
      "2130/2130 [==============================] - 1s 247us/step - loss: 19.5755 - coeff_determination: 0.9683 - val_loss: 69.8853 - val_coeff_determination: 0.7503\n",
      "Epoch 280/400\n",
      "2130/2130 [==============================] - 1s 235us/step - loss: 9.6708 - coeff_determination: 0.9783 - val_loss: 76.5649 - val_coeff_determination: 0.7369\n",
      "Epoch 281/400\n",
      "2130/2130 [==============================] - 1s 235us/step - loss: 6.7710 - coeff_determination: 0.9791 - val_loss: 82.8518 - val_coeff_determination: 0.7540\n",
      "Epoch 282/400\n",
      "2130/2130 [==============================] - 0s 228us/step - loss: 10.3577 - coeff_determination: 0.9726 - val_loss: 63.1450 - val_coeff_determination: 0.7676\n",
      "Epoch 283/400\n",
      "2130/2130 [==============================] - 0s 209us/step - loss: 13.9491 - coeff_determination: 0.9614 - val_loss: 78.9130 - val_coeff_determination: 0.7601\n",
      "Epoch 284/400\n",
      "2130/2130 [==============================] - 0s 202us/step - loss: 27.6467 - coeff_determination: 0.9552 - val_loss: 220.1957 - val_coeff_determination: 0.5990\n",
      "Epoch 285/400\n",
      "2130/2130 [==============================] - 0s 208us/step - loss: 18.4826 - coeff_determination: 0.9595 - val_loss: 101.5370 - val_coeff_determination: 0.7340\n",
      "Epoch 286/400\n",
      "2130/2130 [==============================] - 0s 195us/step - loss: 85.4469 - coeff_determination: 0.9002 - val_loss: 62.4339 - val_coeff_determination: 0.7700\n",
      "Epoch 287/400\n",
      "2130/2130 [==============================] - 0s 211us/step - loss: 18.0124 - coeff_determination: 0.9639 - val_loss: 77.8184 - val_coeff_determination: 0.7613\n",
      "Epoch 288/400\n",
      "2130/2130 [==============================] - 0s 218us/step - loss: 15.2759 - coeff_determination: 0.9715 - val_loss: 68.7812 - val_coeff_determination: 0.7740\n",
      "Epoch 289/400\n",
      "2130/2130 [==============================] - 0s 216us/step - loss: 19.7843 - coeff_determination: 0.9671 - val_loss: 103.5212 - val_coeff_determination: 0.7232\n",
      "Epoch 290/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 18.5189 - coeff_determination: 0.9679 - val_loss: 79.5636 - val_coeff_determination: 0.7763\n",
      "Epoch 291/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 22.6129 - coeff_determination: 0.9593 - val_loss: 109.6471 - val_coeff_determination: 0.7244\n",
      "Epoch 292/400\n",
      "2130/2130 [==============================] - 0s 230us/step - loss: 20.3653 - coeff_determination: 0.9638 - val_loss: 106.1815 - val_coeff_determination: 0.7437\n",
      "Epoch 293/400\n",
      "2130/2130 [==============================] - 0s 215us/step - loss: 14.1731 - coeff_determination: 0.9731 - val_loss: 91.6423 - val_coeff_determination: 0.7493\n",
      "Epoch 294/400\n",
      "2130/2130 [==============================] - 1s 238us/step - loss: 24.4417 - coeff_determination: 0.9694 - val_loss: 101.1539 - val_coeff_determination: 0.7379\n",
      "Epoch 295/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 11.9424 - coeff_determination: 0.9755 - val_loss: 91.0304 - val_coeff_determination: 0.7404\n",
      "Epoch 296/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 15.1222 - coeff_determination: 0.9731 - val_loss: 125.2801 - val_coeff_determination: 0.7082\n",
      "Epoch 297/400\n",
      "2130/2130 [==============================] - 0s 215us/step - loss: 20.5013 - coeff_determination: 0.9702 - val_loss: 93.6380 - val_coeff_determination: 0.7420\n",
      "Epoch 298/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 22.5418 - coeff_determination: 0.9684 - val_loss: 55.5789 - val_coeff_determination: 0.7873\n",
      "Epoch 299/400\n",
      "2130/2130 [==============================] - 0s 215us/step - loss: 47.2073 - coeff_determination: 0.9365 - val_loss: 56.7760 - val_coeff_determination: 0.7687\n",
      "Epoch 300/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 18.0805 - coeff_determination: 0.9651 - val_loss: 85.2462 - val_coeff_determination: 0.7510\n",
      "Epoch 301/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 15.1911 - coeff_determination: 0.9656 - val_loss: 116.6201 - val_coeff_determination: 0.7476\n",
      "Epoch 302/400\n",
      "2130/2130 [==============================] - 0s 220us/step - loss: 12.8156 - coeff_determination: 0.9748 - val_loss: 89.8136 - val_coeff_determination: 0.7451\n",
      "Epoch 303/400\n",
      "2130/2130 [==============================] - 0s 221us/step - loss: 24.4822 - coeff_determination: 0.9666 - val_loss: 75.6742 - val_coeff_determination: 0.7337\n",
      "Epoch 304/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 11.6023 - coeff_determination: 0.9776 - val_loss: 110.7728 - val_coeff_determination: 0.7174\n",
      "Epoch 305/400\n",
      "2130/2130 [==============================] - 1s 239us/step - loss: 17.8387 - coeff_determination: 0.9698 - val_loss: 76.2737 - val_coeff_determination: 0.7631\n",
      "Epoch 306/400\n",
      "2130/2130 [==============================] - 1s 248us/step - loss: 10.4418 - coeff_determination: 0.9770 - val_loss: 111.4637 - val_coeff_determination: 0.7226\n",
      "Epoch 307/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 8.5022 - coeff_determination: 0.9781 - val_loss: 84.8853 - val_coeff_determination: 0.7573\n",
      "Epoch 308/400\n",
      "2130/2130 [==============================] - 0s 223us/step - loss: 19.7949 - coeff_determination: 0.9730 - val_loss: 75.1015 - val_coeff_determination: 0.7707\n",
      "Epoch 309/400\n",
      "2130/2130 [==============================] - 0s 231us/step - loss: 8.9126 - coeff_determination: 0.9796 - val_loss: 86.8119 - val_coeff_determination: 0.7497\n",
      "Epoch 310/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 13.3858 - coeff_determination: 0.9759 - val_loss: 106.1584 - val_coeff_determination: 0.7340\n",
      "Epoch 311/400\n",
      "2130/2130 [==============================] - 0s 222us/step - loss: 13.0954 - coeff_determination: 0.9747 - val_loss: 79.5891 - val_coeff_determination: 0.7657\n",
      "Epoch 312/400\n",
      "2130/2130 [==============================] - 0s 234us/step - loss: 29.4296 - coeff_determination: 0.9639 - val_loss: 60.3289 - val_coeff_determination: 0.7743\n",
      "Epoch 313/400\n",
      "2130/2130 [==============================] - 0s 226us/step - loss: 14.4367 - coeff_determination: 0.9662 - val_loss: 84.7557 - val_coeff_determination: 0.7555\n",
      "Epoch 314/400\n",
      "2130/2130 [==============================] - 1s 236us/step - loss: 23.5213 - coeff_determination: 0.9635 - val_loss: 88.0137 - val_coeff_determination: 0.7234\n",
      "Epoch 315/400\n",
      "2130/2130 [==============================] - 1s 265us/step - loss: 13.3438 - coeff_determination: 0.9736 - val_loss: 116.7223 - val_coeff_determination: 0.7229\n",
      "Epoch 316/400\n",
      "2130/2130 [==============================] - 1s 242us/step - loss: 22.0571 - coeff_determination: 0.9421 - val_loss: 109.9896 - val_coeff_determination: 0.7244\n",
      "Epoch 317/400\n",
      "2130/2130 [==============================] - 1s 265us/step - loss: 23.1135 - coeff_determination: 0.9579 - val_loss: 106.1011 - val_coeff_determination: 0.7222\n",
      "Epoch 318/400\n",
      "2130/2130 [==============================] - 1s 267us/step - loss: 34.6402 - coeff_determination: 0.9572 - val_loss: 94.6492 - val_coeff_determination: 0.7582\n",
      "Epoch 319/400\n",
      "2130/2130 [==============================] - 1s 257us/step - loss: 11.3081 - coeff_determination: 0.9765 - val_loss: 66.6616 - val_coeff_determination: 0.7673\n",
      "Epoch 320/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 12.1086 - coeff_determination: 0.9728 - val_loss: 76.7913 - val_coeff_determination: 0.7553\n",
      "Epoch 321/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 1s 244us/step - loss: 29.8644 - coeff_determination: 0.9557 - val_loss: 77.2012 - val_coeff_determination: 0.7491\n",
      "Epoch 322/400\n",
      "2130/2130 [==============================] - 1s 254us/step - loss: 13.9370 - coeff_determination: 0.9715 - val_loss: 64.9021 - val_coeff_determination: 0.7539\n",
      "Epoch 323/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 12.4681 - coeff_determination: 0.9697 - val_loss: 53.3128 - val_coeff_determination: 0.7884\n",
      "Epoch 324/400\n",
      "2130/2130 [==============================] - 1s 264us/step - loss: 12.2461 - coeff_determination: 0.9726 - val_loss: 131.4472 - val_coeff_determination: 0.7063\n",
      "Epoch 325/400\n",
      "2130/2130 [==============================] - 1s 242us/step - loss: 13.4006 - coeff_determination: 0.9727 - val_loss: 62.9310 - val_coeff_determination: 0.7600\n",
      "Epoch 326/400\n",
      "2130/2130 [==============================] - 1s 243us/step - loss: 12.7071 - coeff_determination: 0.9717 - val_loss: 100.5292 - val_coeff_determination: 0.7261\n",
      "Epoch 327/400\n",
      "2130/2130 [==============================] - 0s 233us/step - loss: 12.0499 - coeff_determination: 0.9732 - val_loss: 54.3284 - val_coeff_determination: 0.7844\n",
      "Epoch 328/400\n",
      "2130/2130 [==============================] - 1s 263us/step - loss: 65.9875 - coeff_determination: 0.9288 - val_loss: 57.6081 - val_coeff_determination: 0.7692\n",
      "Epoch 329/400\n",
      "2130/2130 [==============================] - 0s 232us/step - loss: 14.0055 - coeff_determination: 0.9668 - val_loss: 97.2919 - val_coeff_determination: 0.7410\n",
      "Epoch 330/400\n",
      "2130/2130 [==============================] - 1s 249us/step - loss: 31.6305 - coeff_determination: 0.9571 - val_loss: 58.5918 - val_coeff_determination: 0.7682\n",
      "Epoch 331/400\n",
      "2130/2130 [==============================] - 1s 258us/step - loss: 27.4973 - coeff_determination: 0.9624 - val_loss: 105.2207 - val_coeff_determination: 0.7339\n",
      "Epoch 332/400\n",
      "2130/2130 [==============================] - 1s 237us/step - loss: 41.6220 - coeff_determination: 0.9354 - val_loss: 81.6713 - val_coeff_determination: 0.7712\n",
      "Epoch 333/400\n",
      "1440/2130 [===================>..........] - ETA: 0s - loss: 9.4626 - coeff_determination: 0.9769 "
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(df, 600, 'simple')\n",
    "\n",
    "verbose = 1 # выводить ли инфу в процессе обучения (на гитхаб лучше не заливать когда verbose > 0, а просто перетренировать с = 0)\n",
    "            # 0 - silence \n",
    "            # 1 - progress bar\n",
    "            # 2 - line per epoch \n",
    "model = create_dropout_model(X_train.shape[1])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[coeff_determination])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=400, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 83us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[68.91406753540039, 0.6779361319541931]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_on_test(model, enc='simple'):\n",
    "    df = pd.read_csv('./robot_data/test_data.csv')\n",
    "    df = df.drop(columns=['year', 'target'])\n",
    "    \n",
    "    if enc == 'simple':\n",
    "        df = simple_encode(df.copy())\n",
    "        \n",
    "    elif enc == 'onehot':\n",
    "        df = oneHotEncode(df.copy())\n",
    "        \n",
    "    y_pred = model.predict(df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submition(model, enc='simple', subm_name=None):\n",
    "    df = pd.read_csv('./robot_data/test_data.csv')\n",
    "    years = df['year']\n",
    "    \n",
    "    y_pred = get_preds_on_test(model)\n",
    "    y_pred = y_pred.reshape(1000)\n",
    "    \n",
    "    \n",
    "    d = {'year': years.values, 'target': y_pred}\n",
    "    ans = pd.DataFrame(d)\n",
    "    ans = ans.set_index('year')\n",
    "    print(ans)\n",
    "    subm_name = subm_name if subm_name else 'submission_.csv'\n",
    "    ans.to_csv(subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         target\n",
      "year           \n",
      "5282 -13.278259\n",
      "5283 -16.040136\n",
      "5284 -19.117350\n",
      "5285 -20.228075\n",
      "5286 -19.922838\n",
      "5287 -18.645390\n",
      "5288 -19.675907\n",
      "5289 -18.406223\n",
      "5290 -20.618595\n",
      "5291 -21.231966\n",
      "5292 -21.152273\n",
      "5293 -20.578045\n",
      "5294 -18.423748\n",
      "5295 -12.994398\n",
      "5296 -10.995569\n",
      "5297 -10.950588\n",
      "5298 -11.344562\n",
      "5299  -9.491128\n",
      "5300  -8.498999\n",
      "5301 -15.678307\n",
      "5302  -6.798501\n",
      "5303  -6.413476\n",
      "5304  -7.818804\n",
      "5305  -8.990040\n",
      "5306  -9.916883\n",
      "5307 -14.028955\n",
      "5308 -15.059694\n",
      "5309 -11.120197\n",
      "5310 -11.621145\n",
      "5311 -12.333111\n",
      "...         ...\n",
      "6252 -14.664707\n",
      "6253 -15.011763\n",
      "6254 -12.655294\n",
      "6255 -10.717266\n",
      "6256 -10.490582\n",
      "6257  -9.391224\n",
      "6258  -9.850891\n",
      "6259  -9.044678\n",
      "6260  -6.130199\n",
      "6261  -5.609916\n",
      "6262  -2.094820\n",
      "6263  -2.898294\n",
      "6264  -1.932680\n",
      "6265  -2.486497\n",
      "6266  -7.086571\n",
      "6267  -7.763986\n",
      "6268  -8.485709\n",
      "6269 -10.569044\n",
      "6270 -11.841455\n",
      "6271 -12.094532\n",
      "6272 -13.389515\n",
      "6273 -15.917620\n",
      "6274 -15.614767\n",
      "6275 -15.726152\n",
      "6276 -17.932087\n",
      "6277 -16.443579\n",
      "6278 -14.203053\n",
      "6279 -16.429148\n",
      "6280 -12.717262\n",
      "6281 -10.783751\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "create_submition(model, subm_name='./submissions/subm_mlp_full_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
